<!DOCTYPE html>
<html lang="en" class="h-full">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <meta name="turbo-cache-control" content="no-cache" data-turbo-track="reload" data-track-token="3.11.0.806023909283">

    <!-- See retype.com -->
    <meta name="generator" content="Retype 3.11.0">

    <!-- Primary Meta Tags -->
    <title>27/03/2025</title>
    <meta name="title" content="27/03/2025">
    <meta name="description" content="Installed and configured Ubuntu 20.04 on local laptop with another ssd (dual boot, dual drive)">

    <!-- Canonical -->
    <link rel="canonical" href="/isaac_sim_lab/reports/">

    <!-- Open Graph / Facebook -->
    <meta property="og:type" content="website">
    <meta property="og:url" content="/isaac_sim_lab/reports/">
    <meta property="og:title" content="27/03/2025">
    <meta property="og:description" content="Installed and configured Ubuntu 20.04 on local laptop with another ssd (dual boot, dual drive)">
    <meta property="og:image" content="https://github.com/user-attachments/assets/51068fb5-9b9e-46fe-98f7-35c5f1bb7a78">

    <!-- Twitter -->
    <meta property="twitter:card" content="summary_large_image">
    <meta property="twitter:url" content="/isaac_sim_lab/reports/">
    <meta property="twitter:title" content="27/03/2025">
    <meta property="twitter:description" content="Installed and configured Ubuntu 20.04 on local laptop with another ssd (dual boot, dual drive)">
    <meta property="twitter:image" content="https://github.com/user-attachments/assets/51068fb5-9b9e-46fe-98f7-35c5f1bb7a78">

    <script data-cfasync="false">(function(){var cl=document.documentElement.classList,ls=localStorage.getItem("retype_scheme"),hd=cl.contains("dark"),hl=cl.contains("light"),wm=window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches;if(ls==="dark"||(!ls&&wm&&!hd&&!hl)){cl.remove("light");cl.add("dark")}else if(ls==="light"||(!ls&&!wm&&!hd&&!hl)){cl.remove("dark");cl.add("light")}})();</script>

    <link href="../../static/nuclea-logo.png" rel="icon">
    <link href="../../resources/css/retype.css?v=3.11.0.806023909283" rel="stylesheet">

    <script data-cfasync="false" src="../../resources/js/config.js?v=3.11.0.806023909283" data-turbo-eval="false" defer></script>
    <script data-cfasync="false" src="../../resources/js/retype.js?v=3.11.0" data-turbo-eval="false" defer></script>
    <script id="lunr-js" data-cfasync="false" src="../../resources/js/lunr.js?v=3.11.0.806023909283" data-turbo-eval="false" defer></script>
</head>
<body>
    <div id="retype-app" class="relative text-base antialiased text-base-text bg-base-bg font-body">
        <div class="absolute bottom-0 left-0" style="top: 5rem; right: 50%"></div>
    
        <header id="retype-header" class="sticky top-0 z-30 flex w-full h-16 bg-header-bg border-b border-header-border md:h-20">
            <div class="container relative flex items-center justify-between pr-6 grow md:justify-start">
                <!-- Mobile menu button skeleton -->
                <button v-cloak class="skeleton retype-mobile-menu-button flex items-center justify-center shrink-0 overflow-hidden dark:text-white focus:outline-none rounded-full w-10 h-10 ml-3.5 md:hidden"><svg xmlns="http://www.w3.org/2000/svg" class="mb-px shrink-0" width="24" height="24" viewBox="0 0 24 24" role="presentation" style="margin-bottom: 0px;"><g fill="currentColor"><path d="M2 4h20v2H2zM2 11h20v2H2zM2 18h20v2H2z"></path></g></svg></button>
                <div v-cloak id="retype-sidebar-left-toggle-button"></div>
        
                <!-- Logo -->
                <div class="flex items-center justify-between h-full py-2 md:w-75">
                    <div class="flex items-center px-2 md:px-6">
                        <a id="retype-branding-logo" href="../../" class="flex items-center leading-snug text-2xl">
                            <span class="w-10 mr-2 grow-0 shrink-0 overflow-hidden">
                                <img class="max-h-10 dark:hidden md:inline-block" src="../../static/nuclea-logo.png">
                                <img class="max-h-10 hidden dark:inline-block" src="../../static/nuclea-logo.png">
                            </span>
                            <span class="dark:text-white font-bold line-clamp-1 md:line-clamp-2">Covenant</span>
                        </a><span id="retype-branding-label" class="inline-flex mt-1 px-2 py-1 ml-4 text-xs font-medium leading-none items-center rounded-md bg-branding-label-bg text-branding-label-text ring-1 ring-branding-label-border ring-inset md:inline-block">Docs</span>
                    </div>
        
                    <span class="hidden h-8 border-r md:inline-block border-base-border"></span>
                </div>
        
                <div class="flex justify-between md:grow">
                    <!-- Top Nav -->
                    <nav id="retype-header-nav" class="hidden md:flex">
                        <ul class="flex flex-col mb-4 md:pl-16 md:mb-0 md:flex-row md:items-center">
                            <li class="mr-6">
                                <a class="py-2 md:mb-0 inline-flex items-center text-sm whitespace-nowrap transition-colors duration-200 ease-linear md:text-header-text font-header-text-weight hover:text-header-text-hover" href="https://retype.com/guides/getting-started/">Getting Started</a>
                            </li>
                            <li class="mr-6">
                                <a class="py-2 md:mb-0 inline-flex items-center text-sm whitespace-nowrap transition-colors duration-200 ease-linear md:text-header-text font-header-text-weight hover:text-header-text-hover" href="https://github.com/covenant-org">Repositorios</a>
                            </li>
        
                        </ul>
                    </nav>
        
                    <!-- Header Right Skeleton -->
                    <div v-cloak class="flex justify-end grow skeleton">
        
                        <!-- Search input mock -->
                        <div class="relative hidden w-40 lg:block lg:max-w-sm lg:ml-auto">
                            <div class="absolute flex items-center justify-center h-full pl-3 dark:text-dark-300">
                                <svg xmlns="http://www.w3.org/2000/svg" class="icon-base" width="16" height="16" viewBox="0 0 24 24" aria-labelledby="icon" role="presentation" style="margin-bottom: 1px;"><g fill="currentColor" ><path d="M21.71 20.29l-3.68-3.68A8.963 8.963 0 0020 11c0-4.96-4.04-9-9-9s-9 4.04-9 9 4.04 9 9 9c2.12 0 4.07-.74 5.61-1.97l3.68 3.68c.2.19.45.29.71.29s.51-.1.71-.29c.39-.39.39-1.03 0-1.42zM4 11c0-3.86 3.14-7 7-7s7 3.14 7 7c0 1.92-.78 3.66-2.04 4.93-.01.01-.02.01-.02.01-.01.01-.01.01-.01.02A6.98 6.98 0 0111 18c-3.86 0-7-3.14-7-7z" ></path></g></svg>
                            </div>
                            <input class="w-full h-10 placeholder-search-placeholder transition-colors duration-200 ease-in bg-search-bg border border-transparent rounded md:text-sm hover:border-search-border-hover focus:outline-none focus:border-search-border-focus" style="padding: 0.625rem 0.75rem 0.625rem 2rem" type="text" placeholder="Search">
                        </div>
        
                        <!-- Mobile search button -->
                        <div class="flex items-center justify-center w-10 h-10 lg:hidden">
                            <svg xmlns="http://www.w3.org/2000/svg" class="shrink-0 icon-base" width="20" height="20" viewBox="0 0 24 24" aria-labelledby="icon" role="presentation" style="margin-bottom: 0px;"><g fill="currentColor" ><path d="M21.71 20.29l-3.68-3.68A8.963 8.963 0 0020 11c0-4.96-4.04-9-9-9s-9 4.04-9 9 4.04 9 9 9c2.12 0 4.07-.74 5.61-1.97l3.68 3.68c.2.19.45.29.71.29s.51-.1.71-.29c.39-.39.39-1.03 0-1.42zM4 11c0-3.86 3.14-7 7-7s7 3.14 7 7c0 1.92-.78 3.66-2.04 4.93-.01.01-.02.01-.02.01-.01.01-.01.01-.01.02A6.98 6.98 0 0111 18c-3.86 0-7-3.14-7-7z" ></path></g></svg>
                        </div>
        
                        <!-- Dark mode switch placeholder -->
                        <div class="w-10 h-10 lg:ml-2"></div>
        
                        <!-- History button -->
                        <div class="flex items-center justify-center w-10 h-10" style="margin-right: -0.625rem;">
                            <svg xmlns="http://www.w3.org/2000/svg" class="shrink-0 icon-base" width="22" height="22" viewBox="0 0 24 24" aria-labelledby="icon" role="presentation" style="margin-bottom: 0px;"><g fill="currentColor" ><g ><path d="M12.01 6.01c-.55 0-1 .45-1 1V12a1 1 0 00.4.8l3 2.22a.985.985 0 001.39-.2.996.996 0 00-.21-1.4l-2.6-1.92V7.01c.02-.55-.43-1-.98-1z"></path><path d="M12.01 1.91c-5.33 0-9.69 4.16-10.05 9.4l-.29-.26a.997.997 0 10-1.34 1.48l1.97 1.79c.19.17.43.26.67.26s.48-.09.67-.26l1.97-1.79a.997.997 0 10-1.34-1.48l-.31.28c.34-4.14 3.82-7.41 8.05-7.41 4.46 0 8.08 3.63 8.08 8.09s-3.63 8.08-8.08 8.08c-2.18 0-4.22-.85-5.75-2.4a.996.996 0 10-1.42 1.4 10.02 10.02 0 007.17 2.99c5.56 0 10.08-4.52 10.08-10.08.01-5.56-4.52-10.09-10.08-10.09z"></path></g></g></svg>
                        </div>
                    </div>
        
                    <div v-cloak class="flex justify-end grow">
                        <div id="retype-mobile-search-button"></div>
                        <doc-search-desktop></doc-search-desktop>
        
                        <doc-theme-switch class="lg:ml-2"></doc-theme-switch>
                        <doc-history></doc-history>
                    </div>
                </div>
            </div>
        </header>
    
    
        <div id="retype-container" class="container relative flex bg-white">
            <!-- Sidebar Skeleton -->
            <div v-cloak class="fixed flex flex-col shrink-0 duration-300 ease-in-out bg-sidebar-left-bg border-sidebar-left-border sidebar top-20 w-75 border-r h-screen md:sticky transition-transform skeleton">
            
                <div class="flex items-center h-16 px-6">
                    <input class="w-full h-8 px-3 py-2 transition-colors duration-200 ease-linear bg-filter-bg border border-filter-border rounded shadow-none text-sm focus:outline-none focus:border-filter-border-focus" type="text" placeholder="Filter">
                </div>
            
                <div class="pl-6 mt-1 mb-4">
                    <div class="w-32 h-3 mb-4 bg-skeleton-bg rounded-full loading"></div>
                    <div class="w-48 h-3 mb-4 bg-skeleton-bg rounded-full loading"></div>
                    <div class="w-40 h-3 mb-4 bg-skeleton-bg rounded-full loading"></div>
                    <div class="w-32 h-3 mb-4 bg-skeleton-bg rounded-full loading"></div>
                    <div class="w-48 h-3 mb-4 bg-skeleton-bg rounded-full loading"></div>
                    <div class="w-40 h-3 mb-4 bg-skeleton-bg rounded-full loading"></div>
                </div>
            
                <div class="shrink-0 mt-auto bg-transparent dark:border-base-border">
                    <a class="flex items-center justify-center flex-nowrap h-16 text-gray-350 dark:text-dark-400 hover:text-gray-600 dark:hover:text-dark-300 transition-colors duration-150 ease-in docs-powered-by" target="_blank" href="https://retype.com/" rel="noopener">
                        <span class="text-xs whitespace-nowrap">Powered by</span>
                        <svg xmlns="http://www.w3.org/2000/svg" class="ml-2" fill="currentColor" width="96" height="20" overflow="visible"><path d="M0 0v20h13.59V0H0zm11.15 17.54H2.44V2.46h8.71v15.08zM15.8 20h2.44V4.67L15.8 2.22zM20.45 6.89V20h2.44V9.34z"/><g><path d="M40.16 8.44c0 1.49-.59 2.45-1.75 2.88l2.34 3.32h-2.53l-2.04-2.96h-1.43v2.96h-2.06V5.36h3.5c1.43 0 2.46.24 3.07.73s.9 1.27.9 2.35zm-2.48 1.1c.26-.23.38-.59.38-1.09 0-.5-.13-.84-.4-1.03s-.73-.28-1.39-.28h-1.54v2.75h1.5c.72 0 1.2-.12 1.45-.35zM51.56 5.36V7.2h-4.59v1.91h4.13v1.76h-4.13v1.92h4.74v1.83h-6.79V5.36h6.64zM60.09 7.15v7.48h-2.06V7.15h-2.61V5.36h7.28v1.79h-2.61zM70.81 14.64h-2.06v-3.66l-3.19-5.61h2.23l1.99 3.45 1.99-3.45H74l-3.19 5.61v3.66zM83.99 6.19c.65.55.97 1.4.97 2.55s-.33 1.98-1 2.51-1.68.8-3.04.8h-1.23v2.59h-2.06V5.36h3.26c1.42 0 2.45.28 3.1.83zm-1.51 3.65c.25-.28.37-.69.37-1.22s-.16-.92-.48-1.14c-.32-.23-.82-.34-1.5-.34H79.7v3.12h1.38c.68 0 1.15-.14 1.4-.42zM95.85 5.36V7.2h-4.59v1.91h4.13v1.76h-4.13v1.92H96v1.83h-6.79V5.36h6.64z"/></g></svg>
                    </a>
                </div>
            </div>
            
            <!-- Sidebar component -->
            <doc-sidebar v-cloak>
                <template #sidebar-footer>
                    <div class="shrink-0 mt-auto border-t md:bg-transparent md:border-none dark:border-base-border">
            
                        <div class="py-3 px-6 md:hidden border-b dark:border-base-border">
                            <nav>
                                <ul class="flex flex-wrap justify-center items-center">
                                    <li class="mr-6">
                                        <a class="block py-1 inline-flex items-center text-sm whitespace-nowrap transition-colors duration-200 ease-linear md:text-header-text font-header-text-weight hover:text-header-text-hover" href="https://retype.com/guides/getting-started/">Getting Started</a>
                                    </li>
                                    <li class="mr-6">
                                        <a class="block py-1 inline-flex items-center text-sm whitespace-nowrap transition-colors duration-200 ease-linear md:text-header-text font-header-text-weight hover:text-header-text-hover" href="https://github.com/covenant-org">Repositorios</a>
                                    </li>
            
                                </ul>
                            </nav>
                        </div>
            
                        <a class="flex items-center justify-center flex-nowrap h-16 text-gray-350 dark:text-dark-400 hover:text-gray-600 dark:hover:text-dark-300 transition-colors duration-150 ease-in docs-powered-by" target="_blank" href="https://retype.com/" rel="noopener">
                            <span class="text-xs whitespace-nowrap">Powered by</span>
                            <svg xmlns="http://www.w3.org/2000/svg" class="ml-2" fill="currentColor" width="96" height="20" overflow="visible"><path d="M0 0v20h13.59V0H0zm11.15 17.54H2.44V2.46h8.71v15.08zM15.8 20h2.44V4.67L15.8 2.22zM20.45 6.89V20h2.44V9.34z"/><g><path d="M40.16 8.44c0 1.49-.59 2.45-1.75 2.88l2.34 3.32h-2.53l-2.04-2.96h-1.43v2.96h-2.06V5.36h3.5c1.43 0 2.46.24 3.07.73s.9 1.27.9 2.35zm-2.48 1.1c.26-.23.38-.59.38-1.09 0-.5-.13-.84-.4-1.03s-.73-.28-1.39-.28h-1.54v2.75h1.5c.72 0 1.2-.12 1.45-.35zM51.56 5.36V7.2h-4.59v1.91h4.13v1.76h-4.13v1.92h4.74v1.83h-6.79V5.36h6.64zM60.09 7.15v7.48h-2.06V7.15h-2.61V5.36h7.28v1.79h-2.61zM70.81 14.64h-2.06v-3.66l-3.19-5.61h2.23l1.99 3.45 1.99-3.45H74l-3.19 5.61v3.66zM83.99 6.19c.65.55.97 1.4.97 2.55s-.33 1.98-1 2.51-1.68.8-3.04.8h-1.23v2.59h-2.06V5.36h3.26c1.42 0 2.45.28 3.1.83zm-1.51 3.65c.25-.28.37-.69.37-1.22s-.16-.92-.48-1.14c-.32-.23-.82-.34-1.5-.34H79.7v3.12h1.38c.68 0 1.15-.14 1.4-.42zM95.85 5.36V7.2h-4.59v1.91h4.13v1.76h-4.13v1.92H96v1.83h-6.79V5.36h6.64z"/></g></svg>
                        </a>
                    </div>
                </template>
            </doc-sidebar>
    
            <div class="grow min-w-0 bg-body-bg">
                <!-- Render "toolbar" template here on api pages --><!-- Render page content -->
                <div class="flex">
                    <div id="retype-main" class="min-w-0 p-4 grow md:px-16">
                        <main class="relative pb-12 lg:pt-2">
                            <div class="retype-markdown" id="retype-content">
                                <!-- Rendered if sidebar right is enabled -->
                                <div id="retype-sidebar-right-toggle"></div>
                                <!-- Page content  -->
<doc-anchor-target id="27032025" class="break-words">
    <h1>
        <doc-anchor-trigger class="header-anchor-trigger" to="#27032025">#</doc-anchor-trigger>
        <span>27/03/2025</span>
    </h1>
</doc-anchor-target>
<ul>
<li>Installed and configured Ubuntu 20.04 on local laptop with another ssd (dual boot, dual drive)</li>
<li>Got most of the requirements for Isaac Sim ( lacking VRAM (6.4 -&gt; 8) and RAM (14.4 -&gt; 32 ))</li>
<li>Installed Isaac Sim</li>
</ul>
<doc-anchor-target id="todo">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#todo">#</doc-anchor-trigger>
        <span>Todo:</span>
    </h2>
</doc-anchor-target>
<ul>
<li>Start testing and exploring program</li>
</ul>
<doc-anchor-target id="28032025">
    <h1>
        <doc-anchor-trigger class="header-anchor-trigger" to="#28032025">#</doc-anchor-trigger>
        <span>28/03/2025</span>
    </h1>
</doc-anchor-target>
<ul>
<li>Installed Isaac Lab</li>
<li>Made first tests</li>
<li>Quick start with robotic arm and solid cube</li>
<li>Got performance issues:</li>
<li>&quot;Isaac Sim is not responding&quot; multiple times</li>
<li>High RAM usage (300 Mb left)</li>
<li>OS frozen multiple times</li>
</ul>
<doc-anchor-target id="todo-1">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#todo-1">#</doc-anchor-trigger>
        <span>Todo:</span>
    </h2>
</doc-anchor-target>
<ul>
<li>Check if there&#x27;s a way to increase performance</li>
<li>Keep testing</li>
</ul>
<doc-anchor-target id="31032025">
    <h1>
        <doc-anchor-trigger class="header-anchor-trigger" to="#31032025">#</doc-anchor-trigger>
        <span>31/03/2025</span>
    </h1>
</doc-anchor-target>
<ul>
<li>Installed Nvidia SDK Manager &amp; Docker</li>
<li>Tests of tutorials in Isaac Sim</li>
<li>Worked well in GUI</li>
<li>Problems in interaction with python scripts</li>
<li>Message appearing when trying hot reload in vs code python script:</li>
</ul>
<div class="codeblock-wrapper"><doc-codeblock>
<pre translate="no" class="language-none"><code v-pre class="language-none">2025-04-01 03:13:59 [361,373ms] [Error] [asyncio] Task exception was never retrieved
future: &lt;Task finished name='Task-1922' coro=&lt;BaseSampleUITemplate._on_load_world.&lt;locals&gt;._on_load_world_async() done, defined at /home/vicman/isaacsim/exts/isaacsim.examples.interactive/isaacsim/examples/interactive/base_sample/base_sample_extension.py:107&gt; exception=NameError(&quot;name 'np' is not defined&quot;)&gt;
Traceback (most recent call last):
  File &quot;/home/vicman/isaacsim/exts/isaacsim.examples.interactive/isaacsim/examples/interactive/base_sample/base_sample_extension.py&quot;, line 108, in _on_load_world_async
    await self._sample.load_world_async()
  File &quot;/home/vicman/isaacsim/exts/isaacsim.examples.interactive/isaacsim/examples/interactive/base_sample/base_sample.py&quot;, line 43, in load_world_async
    self.setup_scene()
  File &quot;/home/vicman/isaacsim/exts/isaacsim.examples.interactive/isaacsim/examples/interactive/hello_world/hello_world.py&quot;, line 33, in setup_scene
    position=np.array([0, 0, 1.0]), # Using the current stage units which is in meters by default.
NameError: name 'np' is not defined
</code></pre>
</doc-codeblock></div>
<ul>
<li>Last logs when trying to run <code v-pre>sudo ./python.sh standalone_examples/api/isaacsim.simulation_app/hello_world.py</code></li>
</ul>
<div class="codeblock-wrapper"><doc-codeblock>
<pre translate="no" class="language-none"><code v-pre class="language-none">2025-04-01 03:12:09 [9,676ms] [Warning] [rtx.scenedb.plugin] SceneDbContext : TLAS limit buffer size 8448000128
2025-04-01 03:12:09 [9,676ms] [Warning] [rtx.scenedb.plugin] SceneDbContext : TLAS limit : valid false, within: false
2025-04-01 03:12:09 [9,676ms] [Warning] [rtx.scenedb.plugin] SceneDbContext : TLAS limit : decrement: 167690, decrement size: 8363520384
2025-04-01 03:12:09 [9,676ms] [Warning] [rtx.scenedb.plugin] SceneDbContext : New limit 8508328 (slope: 503, intercept: 13181056)
2025-04-01 03:12:09 [9,676ms] [Warning] [rtx.scenedb.plugin] SceneDbContext : TLAS limit buffer size 4286378240
2025-04-01 03:12:09 [9,676ms] [Warning] [rtx.scenedb.plugin] SceneDbContext : TLAS limit : valid true, within: true
2025-04-01 03:12:09 [9,855ms] [Warning] [omni.usd-abi.plugin] No setting was found for '/rtx-defaults-transient/meshlights/forceDisable'
2025-04-01 03:12:09 [9,911ms] [Warning] [omni.usd-abi.plugin] No setting was found for '/rtx-defaults/post/dlss/execMode'
./python.sh: line 41: 55718 Killed                  $python_exe &quot;$@&quot; $args
There was an error running python</code></pre>
</doc-codeblock></div>
<ul>
<li>Not obvious reason atm</li>
</ul>
<doc-anchor-target id="1042025">
    <h1>
        <doc-anchor-trigger class="header-anchor-trigger" to="#1042025">#</doc-anchor-trigger>
        <span>1/04/2025</span>
    </h1>
</doc-anchor-target>
<ul>
<li>Solved errors from yesterday</li>
<li>There was no clear reason at all</li>
<li>Most likely something went wrong during Isaac Lab instalation</li>
<li>Solution was to reinstall</li>
<li>Made other tutorials in nvidia page</li>
<li>Got performance errors in some of them</li>
<li>Likely cause: Limited VRAM memory in GPU</li>
</ul>
<doc-anchor-target id="activity-report---01042025">
    <h1>
        <doc-anchor-trigger class="header-anchor-trigger" to="#activity-report---01042025">#</doc-anchor-trigger>
        <span>Activity Report - 01/04/2025</span>
    </h1>
</doc-anchor-target>
<p><strong>Email:</strong> <a href="mailto:brandon@nuclea.solutions">brandon@nuclea.solutions</a></p>
<doc-anchor-target id="main-updates">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#main-updates">#</doc-anchor-trigger>
        <span>Main Updates</span>
    </h2>
</doc-anchor-target>
<ul>
<li>Watched all Multi-Camera Tracking tutorials from Nvidia: <a href="https://www.nvidia.com/en-us/on-demand/playlist/playList-62b777fa-766f-4773-8ae4-a70e564d7848/">Nvidia On-Demand</a></li>
<li>Reinstalled Ubuntu 22.04, Isaac Sim, libraries, and drivers to prevent compatibility issues and ensure a clean work environment</li>
<li><p>Encountered issues during initial tracking tests in Isaac Sim, which led me to decide to reinstall everything.</p>
<doc-anchor-target id="activity-report---02042025">
    <h1>
        <doc-anchor-trigger class="header-anchor-trigger" to="#activity-report---02042025">#</doc-anchor-trigger>
        <span>Activity Report - 02/04/2025</span>
    </h1>
</doc-anchor-target>
</li>
</ul>
<p><strong>Email:</strong> <a href="mailto:brandon@nuclea.solutions">brandon@nuclea.solutions</a></p>
<doc-anchor-target id="main-updates-1">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#main-updates-1">#</doc-anchor-trigger>
        <span>Main Updates</span>
    </h2>
</doc-anchor-target>
<ul>
<li><p>An attempt was made to create a virtual machine in Google Cloud Console using Compute Engine, but the following service errors occurred:</p>
<div class="codeblock-wrapper"><doc-codeblock>
<pre translate="no" class="language-none"><code v-pre class="language-none">A n1-standard-4 VM instance with 1 nvidia-tesla-t4 accelerator(s) is currently unavailable in the us-central1-f zone. Alternatively, you can try your request again with a different VM hardware configuration or at a later time. For more information, see the troubleshooting documentation.</code></pre>
</doc-codeblock></div>
</li>
<li><p>An attempt was made to resolve the error by selecting different hosting zones and various server characteristics, but unfortunately, none were successful.
<img src="https://github.com/user-attachments/assets/51068fb5-9b9e-46fe-98f7-35c5f1bb7a78" alt="image" /></p>
</li>
<li><p>Another test will be attempted with AWS to see if it works there.</p>
</li>
</ul>
<doc-anchor-target id="2042025">
    <h1>
        <doc-anchor-trigger class="header-anchor-trigger" to="#2042025">#</doc-anchor-trigger>
        <span>2/04/2025</span>
    </h1>
</doc-anchor-target>
<p>@VicmanGT</p>
<ul>
<li>Tested different included examples and tutorials in isaacsim packate</li>
<li>Got import errors in examples that tried to use clases defined in other folders</li>
<li>Exmaples that didnt&#x27; do that worked correctly</li>
<li>Got initialization error while trying to launch isaac-sim:</li>
</ul>
<div class="codeblock-wrapper"><doc-codeblock>
<pre translate="no" class="language-none"><code v-pre class="language-none">[Error] [carb.cudainterop.plugin] CUDA error 999: cudaErrorUnknown - unknown error)
[Error] [carb.cudainterop.plugin] Failed to query CUDA device count.
[Error] [carb.cudainterop.plugin] Could not query CUDA device.</code></pre>
</doc-codeblock></div>
<ul>
<li>Got temporarly solved by rebooting Ubuntu</li>
<li>Not apparent cause yet.</li>
<li>Error seen in Nvidia Forum:</li>
<li><p><a href="https://forums.developer.nvidia.com/t/cuda-error-999-failed-to-query-cuda-device-count-cuda-deviceordinal-is-invalid/274493">https://forums.developer.nvidia.com/t/cuda-error-999-failed-to-query-cuda-device-count-cuda-deviceordinal-is-invalid/274493</a></p>
<doc-anchor-target id="activity-report---03042025">
    <h1>
        <doc-anchor-trigger class="header-anchor-trigger" to="#activity-report---03042025">#</doc-anchor-trigger>
        <span>Activity Report - 03/04/2025</span>
    </h1>
</doc-anchor-target>
</li>
</ul>
<p><strong>Email:</strong> <a href="mailto:brandon@nuclea.solutions">brandon@nuclea.solutions</a></p>
<doc-anchor-target id="main-updates-2">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#main-updates-2">#</doc-anchor-trigger>
        <span>Main Updates</span>
    </h2>
</doc-anchor-target>
<ul>
<li>Successfully launch and configure a virtual machine on AWS without encountering server issues or GPU availability limitations by region.</li>
<li>The NVIDIA drivers with CUDA and other libraries were installed to configure Metropolitan NVIDIA.</li>
<li><p>An attempt was made to configure Metropolitan NVIDIA using Docker, but the following authorization error occurred:</p>
<div class="codeblock-wrapper"><doc-codeblock>
<pre translate="no" class="language-none"><code v-pre class="language-none">sudo docker login nvcr.io
Username: $oauthtoken
Password:
WARNING! Your password will be stored unencrypted in /root/.docker/config.json.
Configure a credential helper to remove this warning. See
https://docs.docker.com/engine/reference/commandline/login/#credentials-store

Login Succeeded
ubuntu@ip-172-31-5-186:~$ sudo docker pull nvcr.io/nvidia/metropolis/metropolis:v1.0
Error response from daemon: Head &quot;https://nvcr.io/v2/nvidia/metropolis/metropolis/manifests/v1.0&quot;: denied: {&quot;errors&quot;: [{&quot;code&quot;: &quot;DENIED&quot;, &quot;message&quot;: &quot;Access Denied&quot;}]}
ubuntu@ip-172-31-5-186:~$ sudo docker pull nvcr.io/nvidia/metropolis/metropolis:v1.0
Error response from daemon: Head &quot;https://nvcr.io/v2/nvidia/metropolis/metropolis/manifests/v1.0&quot;: denied: {&quot;errors&quot;: [{&quot;code&quot;: &quot;DENIED&quot;, &quot;message&quot;: &quot;Access Denied&quot;}]}</code></pre>
</doc-codeblock></div>
</li>
<li>I used DeepStream SDK as an alternative to Docker to perform intelligent video analysis.</li>
<li>I will look for a way to install it tomorrow using a Docker container for only the VTS service.</li>
</ul>
<doc-anchor-target id="03042025">
    <h1>
        <doc-anchor-trigger class="header-anchor-trigger" to="#03042025">#</doc-anchor-trigger>
        <span>03/04/2025</span>
    </h1>
</doc-anchor-target>
<p>@VicmanGT</p>
<ul>
<li>Check tutorials and examples from Nvidia Isaac Sim docs page</li>
<li>Started reviewing examples from cameras in the simulation</li>
<li>Printed frames into console and generated images from frames with opencv</li>
<li>Combined examples from a robot (car and arm ) simulation and a camera implementation, worked nicely</li>
</ul>
<doc-anchor-target id="todo-2">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#todo-2">#</doc-anchor-trigger>
        <span>Todo:</span>
    </h2>
</doc-anchor-target>
<ul>
<li>Get video from simulation using camera</li>
<li>Check how to put multiple cameras and get data from them</li>
<li><p>Implement in other examples</p>
<doc-anchor-target id="activity-report---04042025">
    <h1>
        <doc-anchor-trigger class="header-anchor-trigger" to="#activity-report---04042025">#</doc-anchor-trigger>
        <span>Activity Report - 04/04/2025</span>
    </h1>
</doc-anchor-target>
</li>
</ul>
<p><strong>Email:</strong> <a href="mailto:brandon@nuclea.solutions">brandon@nuclea.solutions</a></p>
<doc-anchor-target id="main-updates-3">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#main-updates-3">#</doc-anchor-trigger>
        <span>Main Updates</span>
    </h2>
</doc-anchor-target>
<ul>
<li>It was successfully installed and configured DeepStream on the server.</li>
<li>A configuration file was created for DeepStream so that it could run a video through VST.</li>
<li><p>The video ran correctly, but I have the problem of not being able to visualize it since I&#x27;m connected via SSH.</p>
<div class="codeblock-wrapper"><doc-codeblock>
<pre translate="no" class="language-none"><code v-pre class="language-none">ubuntu@ip-172-31-5-186:/opt/nvidia/deepstream/deepstream-7.1/samples/configs/deepstream-app$ deepstream-app -c config_file.txt
** WARN: &lt;parse_source:675&gt;: Unknown key 'width' for group [source0]
** WARN: &lt;parse_source:675&gt;: Unknown key 'height' for group [source0]

Runtime commands:
        h: Print this help
        q: Quit

        p: Pause
        r: Resume

** INFO: &lt;bus_callback:291&gt;: Pipeline ready

Failed to query video capabilities: Invalid argument
** INFO: &lt;bus_callback:277&gt;: Pipeline running

nvstreammux: Successfully handled EOS for source_id=0
** INFO: &lt;bus_callback:334&gt;: Received EOS. Exiting ...

Quitting
App run successful</code></pre>
</doc-codeblock></div>
</li>
<li>Find a way to display the VST UI.</li>
</ul>
<doc-anchor-target id="04042025">
    <h1>
        <doc-anchor-trigger class="header-anchor-trigger" to="#04042025">#</doc-anchor-trigger>
        <span>04/04/2025</span>
    </h1>
</doc-anchor-target>
<p>@VicmanGT</p>
<ul>
<li>Checked humanoids example</li>
<li>Added multiple cameras to simulation in different positions and orientations</li>
<li>Got frames from all of them each a certain amount of time</li>
<li>Converted frames into iamges and store them in file system</li>
<li>Camera 1 first frame
<figure class="content-center">
    <img src="https://github.com/user-attachments/assets/37a655b8-9a6f-457b-8918-6f55e2169369" alt="1_camera1_opencv" class="rounded-image-rounded border-image-border border-image-border-width" />
    <figcaption class="caption">1_camera1_opencv</figcaption>
</figure>
</li>
<li>Camera 2 first frame
<figure class="content-center">
    <img src="https://github.com/user-attachments/assets/c830fc73-fcd9-4da5-9d71-31189e2571df" alt="1_camera2_opencv" class="rounded-image-rounded border-image-border border-image-border-width" />
    <figcaption class="caption">1_camera2_opencv</figcaption>
</figure>
</li>
<li>Camera 3 first frame
<figure class="content-center">
    <img src="https://github.com/user-attachments/assets/b8ab076d-149b-45d7-a03e-695e8c27d0c5" alt="1_camera3_opencv" class="rounded-image-rounded border-image-border border-image-border-width" />
    <figcaption class="caption">1_camera3_opencv</figcaption>
</figure>
</li>
<li>Camera 1 second frame
<figure class="content-center">
    <img src="https://github.com/user-attachments/assets/3d6fab01-d803-4fa3-b8d0-ef112d9e459a" alt="2_camera1_opencv" class="rounded-image-rounded border-image-border border-image-border-width" />
    <figcaption class="caption">2_camera1_opencv</figcaption>
</figure>
</li>
<li>Camera 2 second frame
<figure class="content-center">
    <img src="https://github.com/user-attachments/assets/0c2bcca4-58dd-45c6-a429-9aea0cde91e1" alt="2_camera2_opencv" class="rounded-image-rounded border-image-border border-image-border-width" />
    <figcaption class="caption">2_camera2_opencv</figcaption>
</figure>
</li>
<li>Camera 13 second frame
<figure class="content-center">
    <img src="https://github.com/user-attachments/assets/bd2c523e-719f-428e-9a55-be0f5a101ebf" alt="2_camera3_opencv" class="rounded-image-rounded border-image-border border-image-border-width" />
    <figcaption class="caption">2_camera3_opencv</figcaption>
</figure>
</li>
</ul>
<doc-anchor-target id="todo-3">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#todo-3">#</doc-anchor-trigger>
        <span>Todo:</span>
    </h2>
</doc-anchor-target>
<ul>
<li>Modify humanoid movement to they don&#x27;t fall that quick</li>
</ul>
<doc-anchor-target id="activity-report---07042025">
    <h1>
        <doc-anchor-trigger class="header-anchor-trigger" to="#activity-report---07042025">#</doc-anchor-trigger>
        <span>Activity Report - 07/04/2025</span>
    </h1>
</doc-anchor-target>
<p><strong>Email:</strong> <a href="mailto:brandon@nuclea.solutions">brandon@nuclea.solutions</a></p>
<doc-anchor-target id="main-updates-4">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#main-updates-4">#</doc-anchor-trigger>
        <span>Main Updates</span>
    </h2>
</doc-anchor-target>
<ul>
<li><p>The DeepStream configuration for running MP4 videos has been completed. It runs smoothly, although the interface has not yet been viewed.</p>
</li>
<li><p>The setup for running videos via the RTSP protocol in DeepStream has begun, but it is not yet ready due to the lack of a graphics engine with NVIDIA&#x27;s TensorRT library, which is used for optimizing and running neural networks on GPUs.
<figure class="content-center">
    <img src="https://github.com/user-attachments/assets/b3f1e0b5-b0fb-49e4-a1fc-dfcb1bb0f78a" alt="image" class="rounded-image-rounded border-image-border border-image-border-width" />
    <figcaption class="caption">image</figcaption>
</figure>
</p>
</li>
<li><p>The plan is to follow the quick start guide for multi-camera simulation with AWS, from: <a href="https://docs.nvidia.com/mms/text/Multi_Camera_Sim2Deploy_AWS.html">Multi_Camera_Sim2Deploy_AWS</a></p>
</li>
</ul>
<doc-anchor-target id="07042025">
    <h1>
        <doc-anchor-trigger class="header-anchor-trigger" to="#07042025">#</doc-anchor-trigger>
        <span>07/04/2025</span>
    </h1>
</doc-anchor-target>
<p>@VicmanGT</p>
<ul>
<li>Implemented 3 cameras in different position in humanoid simulation</li>
<li>Got 1 fps from all of them and were saved in different folders</li>
<li>Used numeric keyboard to move the humanoids throughout the space ( now modified to warehouse environment )</li>
<li>Simulation Results (5x vel):</li>
</ul>
<p><a href="https://github.com/user-attachments/assets/857a68e0-6a97-43a5-8a4b-a65aecdfccd5">https://github.com/user-attachments/assets/857a68e0-6a97-43a5-8a4b-a65aecdfccd5</a></p>
<ul>
<li>Cameras frames:</li>
</ul>
<p><a href="https://github.com/user-attachments/assets/37780be7-548c-43ed-ba8e-8d2b6116535b">https://github.com/user-attachments/assets/37780be7-548c-43ed-ba8e-8d2b6116535b</a></p>
<p><a href="https://github.com/user-attachments/assets/055b8177-7941-450b-abac-d18915dcbd03">https://github.com/user-attachments/assets/055b8177-7941-450b-abac-d18915dcbd03</a></p>
<p><a href="https://github.com/user-attachments/assets/f38c2686-e087-4d51-bd08-f0ae348baad8">https://github.com/user-attachments/assets/f38c2686-e087-4d51-bd08-f0ae348baad8</a></p>
<ul>
<li>Got some issues with slowness of the simulation and response time from the keyboard input, posible cause the frame capture</li>
<li>Neither RAM or VRAM seem an cause</li>
</ul>
<doc-anchor-target id="08042025">
    <h1>
        <doc-anchor-trigger class="header-anchor-trigger" to="#08042025">#</doc-anchor-trigger>
        <span>08/04/2025</span>
    </h1>
</doc-anchor-target>
<p>@VicmanGT</p>
<ul>
<li>Implemented RF-DETR algorithm on code to make predicions on the detected frames for each camera</li>
<li>GitHub Repo: <a href="https://github.com/roboflow/rf-detr">https://github.com/roboflow/rf-detr</a></li>
<li>Save the images with surrounding boxes with predictions</li>
<li>Got errors while trying this:</li>
</ul>
<div class="codeblock-wrapper"><doc-codeblock>
<pre translate="no" class="language-none"><code v-pre class="language-none">  Error] [omni.ext._impl.custom_importer] Failed to import python module omni.kit.widget.options_menu. Error: No module named 'omni.kit.widget'</code></pre>
</doc-codeblock></div>
<ul>
<li>This after making a <code v-pre>./python.sh -m pip install rfdetr</code> to install the library to use the model</li>
<li>The error message was showed in console for almost every <code v-pre>omni</code> dependent package</li>
<li>Ran <code v-pre>./post_install.sh</code> after rebooting system</li>
<li><p>New error was this:</p>
<div class="codeblock-wrapper"><doc-codeblock>
<pre translate="no" class="language-none"><code v-pre class="language-none">[Error] [carb.scripting-python.plugin] FileNotFoundError: [Errno 2] No such file or directory: '/home/vicman/isaacsim/exts/omni.pip.compute/pip_prebundle/cv2'
At:
  /home/vicman/isaacsim/kit/kernel/py/omni/ext/_impl/fast_importer.py(261): _fast_walk</code></pre>
</doc-codeblock></div>
</li>
<li>Neither the application of any of the examples from isaac sim worked due to the same error</li>
<li>Couldn&#x27;t yet find a quick solution in the web</li>
</ul>
<doc-anchor-target id="todo-4">
    <h1>
        <doc-anchor-trigger class="header-anchor-trigger" to="#todo-4">#</doc-anchor-trigger>
        <span>Todo:</span>
    </h1>
</doc-anchor-target>
<ul>
<li>Reinstall Isaac Sim from scratch</li>
<li>Check installed python libraries with  <code v-pre>./python.sh -m pip list</code> before and after trying to install the <code v-pre>rfdeter</code></li>
</ul>
<doc-anchor-target id="activity-report---09042025">
    <h1>
        <doc-anchor-trigger class="header-anchor-trigger" to="#activity-report---09042025">#</doc-anchor-trigger>
        <span>Activity Report - 09/04/2025</span>
    </h1>
</doc-anchor-target>
<p><strong>Email:</strong> <a href="mailto:brandon@nuclea.solutions">brandon@nuclea.solutions</a></p>
<doc-anchor-target id="main-updates-5">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#main-updates-5">#</doc-anchor-trigger>
        <span>Main Updates</span>
    </h2>
</doc-anchor-target>
<ul>
<li><p>Early access was requested from NVIDIA through an official application to use their new AI models and camera tracking technologies, such as NVIDIA Metropolis. I am currently waiting for approval.
<figure class="content-center">
    <img src="https://github.com/user-attachments/assets/22eba68c-ff38-463e-80f9-f64dbd7196c0" alt="image" class="rounded-image-rounded border-image-border border-image-border-width" />
    <figcaption class="caption">image</figcaption>
</figure>
</p>
</li>
<li><p>Two work plans were developed to extract video footage from HikVision cameras. The first plan involves downloading videos locally via RTSP using the FFmpeg library. A Python script was created to manage all registered cameras listed in a CSV file. The recording duration is customizable, and using cron jobs and system services, we can schedule the script to run at specific times of the day.
<figure class="content-center">
    <img src="https://github.com/user-attachments/assets/26ba5144-9e2c-4c90-9b22-75390956852b" alt="image" class="rounded-image-rounded border-image-border border-image-border-width" />
    <figcaption class="caption">image</figcaption>
</figure>
</p>
</li>
<li><p>The second plan builds on the first but differs in that instead of storing the videos locally, the footage is uploaded directly to a cloud storage solution such as an AWS S3 bucket.</p>
</li>
<li><p>Tomorrow, we will begin testing with the actual Fimex cameras and evaluate the strategy of also using an SFTP server to store all videos, which will later be processed using NVIDIA Metropolis.</p>
</li>
</ul>
<doc-anchor-target id="09042025">
    <h1>
        <doc-anchor-trigger class="header-anchor-trigger" to="#09042025">#</doc-anchor-trigger>
        <span>09/04/2025</span>
    </h1>
</doc-anchor-target>
<p>@VicmanGT</p>
<ul>
<li>Reinstalled Isaac Sim and the problem from yesterdy solved, even after installiing de library for the RF-DETR</li>
<li>Correctly implemented RF-DETR algorithm</li>
<li>Correctly saved frames with bounding boxes of predicitons</li>
<li>Improved performance of simulation by lowering the resolution of the cameras (full hd -&gt; hd)</li>
<li>Moved camera positions to get them to capture a wider space</li>
<li>Implemented an option to choose between automated simulation of manual control with the numpad</li>
<li>Started coding the algorithm to detect movement</li>
<li>Results of simulation:</li>
</ul>
<p><a href="https://github.com/user-attachments/assets/2f4ab757-2c00-4ba6-847a-94ed0731e8e0">https://github.com/user-attachments/assets/2f4ab757-2c00-4ba6-847a-94ed0731e8e0</a></p>
<ul>
<li>Result frames with predicitons</li>
</ul>
<p><a href="https://github.com/user-attachments/assets/0ff68486-a04d-4fbf-9df4-60e08fe3807f">https://github.com/user-attachments/assets/0ff68486-a04d-4fbf-9df4-60e08fe3807f</a></p>
<p><a href="https://github.com/user-attachments/assets/85516f4c-dab2-4da7-a751-920e4efccdc5">https://github.com/user-attachments/assets/85516f4c-dab2-4da7-a751-920e4efccdc5</a></p>
<doc-anchor-target id="todo-5">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#todo-5">#</doc-anchor-trigger>
        <span>Todo:</span>
    </h2>
</doc-anchor-target>
<ul>
<li>The RF-DETR algorithm had problems to identify the humanoids, labeling them as other objects when they were even detected</li>
<li>This could be mainly due to the not human like texture they have, so try to find if there&#x27;s another texture to cover them</li>
<li>Check another object detection algorithm such as YOLO to compare performance and scores</li>
<li>Implement the move alert function</li>
<li>Figure out how to mantain some form of consistency during the frames passed</li>
</ul>
<doc-anchor-target id="notes">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#notes">#</doc-anchor-trigger>
        <span>Notes:</span>
    </h2>
</doc-anchor-target>
<ul>
<li>Got this error message some times while trying to run the python script</li>
</ul>
<div class="codeblock-wrapper"><doc-codeblock>
<pre translate="no" class="language-none"><code v-pre class="language-none">Inconsistency detected by ld.so: ../elf/dl-tls.c: 517: _dl_allocate_tls_init: Assertion `listp != NULL' failed!
There was an error running python</code></pre>
</doc-codeblock></div>
<ul>
<li>The problem solved trying 2 or 1 more time, no obvious reason atm</li>
</ul>
<doc-anchor-target id="activity-report---10042025">
    <h1>
        <doc-anchor-trigger class="header-anchor-trigger" to="#activity-report---10042025">#</doc-anchor-trigger>
        <span>Activity Report - 10/04/2025</span>
    </h1>
</doc-anchor-target>
<p><strong>Email:</strong> <a href="mailto:brandon@nuclea.solutions">brandon@nuclea.solutions</a>
@VicmanGT</p>
<doc-anchor-target id="main-updates-6">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#main-updates-6">#</doc-anchor-trigger>
        <span>Main Updates</span>
    </h2>
</doc-anchor-target>
<ul>
<li>Today, I visited the Fimex factory and worked with Víctor on configuring and extracting video footage from the production cameras, then streaming it via RTSP to the AWS EC2.</li>
<li>Checked the stream via VLC, however this was only possible in Brandon&#x27;s personal computer most likely because some specific configuration on the Local Fimex computer.</li>
<li>It did work one time on the Local Fimex computer but after changing the camera in the python script, the connection was unable to be setted again, the reason behind this it&#x27;s still not clear.</li>
<li>We also left the local Fimex computer connected to TeamViewer, so we can access it remotely in the future for further configuration.</li>
</ul>
<doc-anchor-target id="activity-report---11042025">
    <h1>
        <doc-anchor-trigger class="header-anchor-trigger" to="#activity-report---11042025">#</doc-anchor-trigger>
        <span>Activity Report - 11/04/2025</span>
    </h1>
</doc-anchor-target>
<p><strong>Email:</strong> <a href="mailto:brandon@nuclea.solutions">brandon@nuclea.solutions</a></p>
<doc-anchor-target id="main-updates-7">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#main-updates-7">#</doc-anchor-trigger>
        <span>Main Updates</span>
    </h2>
</doc-anchor-target>
<ul>
<li>A basic GUI was downloaded and configured for the AWS EC2 server, and a successful connection was made from a Windows client machine using VNC.
<img src="https://github.com/user-attachments/assets/ba528233-23b5-4b30-acd5-e41a2f78b674" alt="image" /></li>
<li>A daemon service was created so that, upon starting or restarting the server, the mediamtx service would automatically start and run, enabling the reception of video from the RTSP cameras.</li>
<li>A VPN called Kerio was downloaded and configured on the virtual machine to establish a connection between the server and the local Fimex computer.
<figure class="content-center">
    <img src="https://github.com/user-attachments/assets/6ef47ec7-2bf9-4525-92ac-a7fdfbbb711b" alt="image" class="rounded-image-rounded border-image-border border-image-border-width" />
    <figcaption class="caption">image</figcaption>
</figure>
</li>
<li>A visit was made to Cumbres to perform a drone flight test.</li>
</ul>
<doc-anchor-target id="11042025">
    <h1>
        <doc-anchor-trigger class="header-anchor-trigger" to="#11042025">#</doc-anchor-trigger>
        <span>11/04/2025</span>
    </h1>
</doc-anchor-target>
<p>@VicmanGT</p>
<ul>
<li>Went to Cumbres school to help install and configure a sensor to better measure the distance from the ground</li>
<li>Helped performed basic flight operation</li>
</ul>
<doc-anchor-target id="activity-report---14042025">
    <h1>
        <doc-anchor-trigger class="header-anchor-trigger" to="#activity-report---14042025">#</doc-anchor-trigger>
        <span>Activity Report - 14/04/2025</span>
    </h1>
</doc-anchor-target>
<p><strong>Email:</strong> <a href="mailto:brandon@nuclea.solutions">brandon@nuclea.solutions</a></p>
<doc-anchor-target id="main-updates-8">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#main-updates-8">#</doc-anchor-trigger>
        <span>Main Updates</span>
    </h2>
</doc-anchor-target>
<ul>
<li><p>Once the VPN was correctly installed and configured on the EC2 server, a service was also created to enable it and connect automatically to the Fimex server every time the server starts.</p>
</li>
<li><p>A service was created so that VNC would start automatically when Linux boots, allowing us to access the graphical interface without having to activate it manually.</p>
</li>
<li><p>It was possible to ping the IP address 172.16.3.122, and the camera stream could already be viewed using the ffplay command.
<img src="https://github.com/user-attachments/assets/941a9674-cd8a-4e63-ac20-b4f2331a6edf" alt="image" />
<img src="https://github.com/user-attachments/assets/2c27eb72-acce-4f45-878b-b426bd0766b9" alt="image" /></p>
</li>
<li><p>It will be investigated how to save short video locally to process it on the EC2 server.</p>
</li>
</ul>
<doc-anchor-target id="14042025">
    <h1>
        <doc-anchor-trigger class="header-anchor-trigger" to="#14042025">#</doc-anchor-trigger>
        <span>14/04/2025</span>
    </h1>
</doc-anchor-target>
<p>@VicmanGT</p>
<ul>
<li>Coded a movement alert function that prints to the console when the centroid of a box prediction moves more that a certain threshold</li>
<li>Included logging info to know when the new object are detected, not longer detected or the classs of the prediction changed</li>
<li>Also when there are no predictions for the image</li>
<li>All this for each camera</li>
</ul>
<p><a href="https://github.com/user-attachments/assets/be6eac17-51a7-4254-bc91-5e1aee0add30">https://github.com/user-attachments/assets/be6eac17-51a7-4254-bc91-5e1aee0add30</a></p>
<ul>
<li>Implemented YOLOv11 model to make predictions on frames</li>
</ul>
<doc-anchor-target id="todo-6">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#todo-6">#</doc-anchor-trigger>
        <span>Todo:</span>
    </h2>
</doc-anchor-target>
<ul>
<li>Check how to process the outputs of YOLOv11 to draw the rectangles on the image</li>
<li><p>Adapt function to process the output of YOLOv11</p>
<doc-anchor-target id="activity-report---15042025">
    <h1>
        <doc-anchor-trigger class="header-anchor-trigger" to="#activity-report---15042025">#</doc-anchor-trigger>
        <span>Activity Report - 15/04/2025</span>
    </h1>
</doc-anchor-target>
</li>
</ul>
<p><strong>Email:</strong> <a href="mailto:brandon@nuclea.solutions">brandon@nuclea.solutions</a></p>
<doc-anchor-target id="main-updates-9">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#main-updates-9">#</doc-anchor-trigger>
        <span>Main Updates</span>
    </h2>
</doc-anchor-target>
<ul>
<li>Some issues were fixed during the VPN initialization that were preventing it from properly connecting to the Fimex server.</li>
<li>After successfully configuring the VPN to access all camera streams from Fimex, a Python script was developed to extract specific segments of the live feed and save them locally on the computer.
<img src="https://github.com/user-attachments/assets/ba3c9a23-3abf-4aaf-b5ee-c2ea8084ce72" alt="image" />
<img src="https://github.com/user-attachments/assets/a07dd569-bb52-4832-a51d-3b16e876fb69" alt="image" /></li>
<li>The script will be improved to analyze each of the extracted videos for camera tracking. A more local solution will be implemented, without using NVIDIA Metropolis, since access to the platform has not yet been granted.</li>
</ul>
<doc-anchor-target id="15042025">
    <h1>
        <doc-anchor-trigger class="header-anchor-trigger" to="#15042025">#</doc-anchor-trigger>
        <span>15/04/2025</span>
    </h1>
</doc-anchor-target>
<p>@VicmanGT</p>
<ul>
<li>Created repo to have version control in isaac sim code</li>
<li>Completely implemented YOLOv11 algorithm to make predictions for the isaac sim simulation</li>
<li>Assigned camera 2 to this</li>
<li>Tests results:</li>
<li>The YOLO algorithm performed worse than the RFDE, since in most of the frames none of the humanoids were detected</li>
<li>Therefore no moment whatsoever</li>
</ul>
<p><a href="https://github.com/user-attachments/assets/e668101a-0287-4461-b6dc-8672fbc261bc">https://github.com/user-attachments/assets/e668101a-0287-4461-b6dc-8672fbc261bc</a></p>
<ul>
<li>Tested movement alert function in local webcam to check with &quot;real person movement&quot; worked nicely</li>
</ul>
<p><a href="https://github.com/user-attachments/assets/419b049d-e30c-460f-8943-aa1d6a6a3602">https://github.com/user-attachments/assets/419b049d-e30c-460f-8943-aa1d6a6a3602</a></p>
<doc-anchor-target id="todo-7">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#todo-7">#</doc-anchor-trigger>
        <span>Todo:</span>
    </h2>
</doc-anchor-target>
<ul>
<li>Apply filter for person class and counting</li>
</ul>
<doc-anchor-target id="16042025">
    <h1>
        <doc-anchor-trigger class="header-anchor-trigger" to="#16042025">#</doc-anchor-trigger>
        <span>16/04/2025</span>
    </h1>
</doc-anchor-target>
<p>@VicmanGT</p>
<ul>
<li>Divided humanoid simulation file into modules for more comfortable development</li>
<li>Added named paratemer to script to select the model to use (rf-dert or yolo)</li>
<li>IsaacSim code stop working in local computer</li>
<li>Got same error as in the 8/04/2025 but the procedure didn&#x27;t work now</li>
<li>Not custom humanoids simulation app or any of the examples are running:</li>
<li>Last logs before shooting down app:</li>
</ul>
<div class="codeblock-wrapper"><doc-codeblock>
<pre translate="no" class="language-none"><code v-pre class="language-none">2025-04-17 01:31:37 [10,558ms] [Warning] [rtx.scenedb.plugin] SceneDbContext : TLAS limit buffer size 8448000128
2025-04-17 01:31:37 [10,558ms] [Warning] [rtx.scenedb.plugin] SceneDbContext : TLAS limit : valid false, within: false
2025-04-17 01:31:37 [10,558ms] [Warning] [rtx.scenedb.plugin] SceneDbContext : TLAS limit : decrement: 167690, decrement size: 8363520384
2025-04-17 01:31:37 [10,558ms] [Warning] [rtx.scenedb.plugin] SceneDbContext : New limit 8508328 (slope: 503, intercept: 13181056)
2025-04-17 01:31:37 [10,558ms] [Warning] [rtx.scenedb.plugin] SceneDbContext : TLAS limit buffer size 4286378240
2025-04-17 01:31:37 [10,558ms] [Warning] [rtx.scenedb.plugin] SceneDbContext : TLAS limit : valid true, within: true
2025-04-17 01:31:38 [10,757ms] [Warning] [omni.usd-abi.plugin] No setting was found for '/rtx-defaults-transient/meshlights/forceDisable'
2025-04-17 01:31:38 [10,854ms] [Warning] [omni.usd-abi.plugin] No setting was found for '/rtx-defaults/post/dlss/execMode'
./python.sh: line 41: 16648 Killed                  $python_exe &quot;$@&quot; $args
There was an error running python</code></pre>
</doc-codeblock></div>
<ul>
<li>Get frozen while trying to run then suddenly stops</li>
<li>IsaacSim App selector works ok</li>
</ul>
<doc-anchor-target id="todo-8">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#todo-8">#</doc-anchor-trigger>
        <span>Todo:</span>
    </h2>
</doc-anchor-target>
<ul>
<li>Check RAM and VRAM usage while trying to run a script</li>
<li><p>Check other versions</p>
<doc-anchor-target id="activity-report---21042025">
    <h1>
        <doc-anchor-trigger class="header-anchor-trigger" to="#activity-report---21042025">#</doc-anchor-trigger>
        <span>Activity Report - 21/04/2025</span>
    </h1>
</doc-anchor-target>
</li>
</ul>
<p><strong>Email:</strong> <a href="mailto:brandon@nuclea.solutions">brandon@nuclea.solutions</a></p>
<doc-anchor-target id="main-updates-10">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#main-updates-10">#</doc-anchor-trigger>
        <span>Main Updates</span>
    </h2>
</doc-anchor-target>
<ul>
<li>Tests were conducted with the cameras to extract videos from Fimex.</li>
<li>A new VNC service was enabled to allow faster and more efficient access to the server.</li>
<li>A service was created to retry the VPN connection to prevent potential data leaks and to improve video retrieval from the cameras.</li>
<li><p>A solution will be explored to extract all videos from all cameras via streaming and store them in a bucket with a UI to view the streams simultaneously.</p>
<doc-anchor-target id="activity-report---22042025">
    <h1>
        <doc-anchor-trigger class="header-anchor-trigger" to="#activity-report---22042025">#</doc-anchor-trigger>
        <span>Activity Report - 22/04/2025</span>
    </h1>
</doc-anchor-target>
</li>
</ul>
<p><strong>Email:</strong> <a href="mailto:brandon@nuclea.solutions">brandon@nuclea.solutions</a></p>
<doc-anchor-target id="main-updates-11">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#main-updates-11">#</doc-anchor-trigger>
        <span>Main Updates</span>
    </h2>
</doc-anchor-target>
<ul>
<li>A Python script was created to display the streaming of the 20 cameras connected in Fimex through a simple UI.
<img src="https://github.com/user-attachments/assets/dc7d7e4b-338e-4c9c-b1ba-a1b8c1bbded0" alt="image" /></li>
<li>Another script was developed to continuously save the camera streams to an AWS S3 bucket. Whether the recording day ends or the script is interrupted due to an error, the recorded footage up to that point is saved automatically.</li>
<li>A Linux service was configured to ensure the script runs automatically at all times, without the need for manual startup.</li>
<li>The setup of a local computer with a 5070 graphics card will begin, aiming to eliminate the need for using AWS EC2 instances.</li>
</ul>
<doc-anchor-target id="22042025">
    <h1>
        <doc-anchor-trigger class="header-anchor-trigger" to="#22042025">#</doc-anchor-trigger>
        <span>22/04/2025</span>
    </h1>
</doc-anchor-target>
<p>@VicmanGT</p>
<ul>
<li>Tested custom models with the people counting function and the movement alert:</li>
<li>best.pt</li>
</ul>
<p><a href="https://github.com/user-attachments/assets/8ae3f7ba-64e9-4b74-9b0e-67b2b45cc418">https://github.com/user-attachments/assets/8ae3f7ba-64e9-4b74-9b0e-67b2b45cc418</a></p>
<ul>
<li>NucleaDrone-v14-2Class.pt</li>
</ul>
<p><a href="https://github.com/user-attachments/assets/32f82b47-f2f7-4d12-9719-09a25f5dac72">https://github.com/user-attachments/assets/32f82b47-f2f7-4d12-9719-09a25f5dac72</a></p>
<ul>
<li>Both models got similar results</li>
<li>Only minor difference is that best.pt is faster and therefore better and keeping track of people when do fast movements</li>
</ul>
<doc-anchor-target id="23042025">
    <h1>
        <doc-anchor-trigger class="header-anchor-trigger" to="#23042025">#</doc-anchor-trigger>
        <span>23/04/2025</span>
    </h1>
</doc-anchor-target>
<p>@VicmanGT</p>
<ul>
<li>Cloned metropolis-dev repository into ec2 server to access compute there</li>
<li>Made predictions in videos of Fimex with rfde-tf, custom models best.pt and NucleaDrone-v14-2Class.pt</li>
<li>The rf-detr permormed well both at counting and the interaction with the movement_alert</li>
</ul>
<p><a href="https://github.com/user-attachments/assets/e4544a9c-d994-498d-8d65-57ae532acdf7">https://github.com/user-attachments/assets/e4544a9c-d994-498d-8d65-57ae532acdf7</a></p>
<ul>
<li>The tests made with both best.pt and NucleaDrone-v14-2Class.pt seemed to have less accuracy when detecting people, and only outputed one person in each frame</li>
</ul>
<doc-anchor-target id="todo-9">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#todo-9">#</doc-anchor-trigger>
        <span>Todo:</span>
    </h2>
</doc-anchor-target>
<ul>
<li>Check what is happening there</li>
</ul>
<doc-anchor-target id="activity-report---24042025">
    <h1>
        <doc-anchor-trigger class="header-anchor-trigger" to="#activity-report---24042025">#</doc-anchor-trigger>
        <span>Activity Report - 24/04/2025</span>
    </h1>
</doc-anchor-target>
<p><strong>Email:</strong> <a href="mailto:brandon@nuclea.solutions">brandon@nuclea.solutions</a></p>
<doc-anchor-target id="main-updates-12">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#main-updates-12">#</doc-anchor-trigger>
        <span>Main Updates</span>
    </h2>
</doc-anchor-target>
<ul>
<li>The local Nuclea computer with an Nvidia 5070 graphics card was configured to access the Fimex cameras.</li>
<li>VPN and VNC services were created to enable access to the FSTP video from the cameras.</li>
<li>A script was created to run automatically and locally save the video stream from 20 cameras on the computer.</li>
</ul>
<doc-anchor-target id="24042025">
    <h1>
        <doc-anchor-trigger class="header-anchor-trigger" to="#24042025">#</doc-anchor-trigger>
        <span>24/04/2025</span>
    </h1>
</doc-anchor-target>
<p>@VicmanGT</p>
<ul>
<li>Corrected script to get better predictions from custom models best.pt and NucleaDrone-v14-2Class.pt</li>
<li>Tested with videos saved from Fimex cameras</li>
<li>best.pt</li>
</ul>
<p><a href="https://github.com/user-attachments/assets/4187d91b-af04-4b4d-a9da-73f096d703f7">https://github.com/user-attachments/assets/4187d91b-af04-4b4d-a9da-73f096d703f7</a></p>
<ul>
<li>NucleaDrone-v14-2Class.pt</li>
</ul>
<p><a href="https://github.com/user-attachments/assets/15da1964-4ead-43fd-9658-97365a215acb">https://github.com/user-attachments/assets/15da1964-4ead-43fd-9658-97365a215acb</a></p>
<ul>
<li>Between the two custom models, best.pt got the better results being faster and more accurate</li>
<li>When comparing best.pt with the rf-dert model, both provide good results with the main difference that best.pt sometimes detect more people in the frame however rf-dert got more consistent and stable predictions.</li>
</ul>
<doc-anchor-target id="activity-report---25042025">
    <h1>
        <doc-anchor-trigger class="header-anchor-trigger" to="#activity-report---25042025">#</doc-anchor-trigger>
        <span>Activity Report - 25/04/2025</span>
    </h1>
</doc-anchor-target>
<p><strong>Email:</strong> <a href="mailto:brandon@nuclea.solutions">brandon@nuclea.solutions</a></p>
<doc-anchor-target id="main-updates-13">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#main-updates-13">#</doc-anchor-trigger>
        <span>Main Updates</span>
    </h2>
</doc-anchor-target>
<ul>
<li>The advanced configuration was completed for the Zeus computer to enable remote access to its operating system&#x27;s UI via VNC.
<img src="https://github.com/user-attachments/assets/becc8c76-f4d1-4bb8-97b2-6b0b34647f48" alt="image" /></li>
<li>The Python script was improved to more efficiently detect recordings or streamings from the cameras simultaneously and correctly save the video output.</li>
<li>The configuration of the Gaia computer is planned to be completed next, with the goal of enabling remote UI access and beginning the installation of software such as Isaac Sim and Isaac Lab.</li>
</ul>
<doc-anchor-target id="25042025">
    <h1>
        <doc-anchor-trigger class="header-anchor-trigger" to="#25042025">#</doc-anchor-trigger>
        <span>25/04/2025</span>
    </h1>
</doc-anchor-target>
<p>@VicmanGT</p>
<ul>
<li>Reestructured scripts in metropolis-dev repo into folders</li>
<li>isaac_sim_lab, models ( custom models ), utils ( movement alert and function to annotate yolo detections), and video_analysis</li>
<li>In video_analysis added separate scripts to test models in webcam and with a folder with videos</li>
</ul>
<doc-anchor-target id="activity-report---28042025">
    <h1>
        <doc-anchor-trigger class="header-anchor-trigger" to="#activity-report---28042025">#</doc-anchor-trigger>
        <span>Activity Report - 28/04/2025</span>
    </h1>
</doc-anchor-target>
<p><strong>Email:</strong> <a href="mailto:brandon@nuclea.solutions">brandon@nuclea.solutions</a></p>
<doc-anchor-target id="main-updates-14">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#main-updates-14">#</doc-anchor-trigger>
        <span>Main Updates</span>
    </h2>
</doc-anchor-target>
<ul>
<li>The new 14TB hard drive was configured and partitioned for the Zeus computer, and a shortcut was created for this drive in the file explorer.</li>
<li>The script for recording FIMEX cameras was modified to save all videos on the new hard drive.</li>
<li>All the initial configurations for the Gaia computer were completed to enable access to the operating system&#x27;s GUI via a VNC service. Additionally, basic programs such as Visual Studio Code, VLC, Google Chrome, and others were installed.
<img src="https://github.com/user-attachments/assets/22bfd274-0db1-42f8-911b-17eccd385235" alt="image" /></li>
</ul>
<doc-anchor-target id="28042025">
    <h1>
        <doc-anchor-trigger class="header-anchor-trigger" to="#28042025">#</doc-anchor-trigger>
        <span>28/04/2025</span>
    </h1>
</doc-anchor-target>
<p>@VicmanGT</p>
<ul>
<li>Cloned local repository from metropolis-dev and adapted code in the Zeus computer for testing the movement alert in the recordings from Fimex</li>
<li>Got following errors:</li>
</ul>
<div class="codeblock-wrapper"><doc-codeblock>
<pre translate="no" class="language-none"><code v-pre class="language-none">UserWarning: 
NVIDIA GeForce RTX 5070 Ti with CUDA capability sm_120 is not compatible with the current PyTorch installation.
The current PyTorch install supports CUDA capabilities sm_50 sm_60 sm_70 sm_75 sm_80 sm_86 sm_90.
If you want to use the NVIDIA GeForce RTX 5070 Ti GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/</code></pre>
</doc-codeblock></div>
<div class="codeblock-wrapper"><doc-codeblock>
<pre translate="no" class="language-none"><code v-pre class="language-none">RuntimeError: CUDA error: no kernel image is available for execution on the device
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.</code></pre>
</doc-codeblock></div>
<ul>
<li>Seemed like there isn&#x27;t yet any Pytorch version that supports the installed GPU <code v-pre>NVIDIA GeForce RTX 5070 Ti</code> and therefore no models can be used</li>
<li>This happens for both custom models and rf-detr</li>
<li>Relevant links of same problem but using ComfyUI:</li>
</ul>
<ol>
<li><a href="https://github.com/comfyanonymous/ComfyUI/issues/7127">https://github.com/comfyanonymous/ComfyUI/issues/7127</a></li>
<li><a href="https://github.com/comfyanonymous/ComfyUI/discussions/6643">https://github.com/comfyanonymous/ComfyUI/discussions/6643</a></li>
</ol>
<ul>
<li>Solved by installing another pytorch version:</li>
</ul>
<div class="codeblock-wrapper"><doc-codeblock>
<pre translate="no" class="language-none"><code v-pre class="language-none">  pip install --pre torch torchvision --index-url https://download.pytorch.org/whl/nightly/cu128</code></pre>
</doc-codeblock></div>
<p>Results:</p>
<ul>
<li>Very similar to the ones made in the EC2 instance, however there were many videos that had a lot of noise that made the detections inaccurate and inconsistent</li>
<li>Example:</li>
</ul>
<p><a href="https://github.com/user-attachments/assets/5ffefcec-4474-4f50-bb0e-d34da1fe724d">https://github.com/user-attachments/assets/5ffefcec-4474-4f50-bb0e-d34da1fe724d</a></p>
<ul>
<li>But it seems like it&#x27;s more of a problem of the cameras themselves.</li>
</ul>
<doc-anchor-target id="activity-report---29042025">
    <h1>
        <doc-anchor-trigger class="header-anchor-trigger" to="#activity-report---29042025">#</doc-anchor-trigger>
        <span>Activity Report - 29/04/2025</span>
    </h1>
</doc-anchor-target>
<p><strong>Email:</strong> <a href="mailto:brandon@nuclea.solutions">brandon@nuclea.solutions</a></p>
<doc-anchor-target id="main-updates-15">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#main-updates-15">#</doc-anchor-trigger>
        <span>Main Updates</span>
    </h2>
</doc-anchor-target>
<ul>
<li>Isaac Sim and Isaac Lab from NVIDIA were downloaded and configured on the Gaia computer.
<img src="https://github.com/user-attachments/assets/c7ef6658-3858-47db-8f47-4ec3409a4132" alt="image" /></li>
<li>The first test of using the VST container on the Zeus computer for elk tracking with the office webcam was conducted.</li>
<li>The VST Docker container runs correctly, but there is an issue where the UI does not display, even though no specific error is thrown. Further investigation is needed to find a way to launch it properly.
<img src="https://github.com/user-attachments/assets/6693eeed-04f8-4efe-9389-94fe007eb558" alt="image" /></li>
</ul>
<doc-anchor-target id="29042025">
    <h1>
        <doc-anchor-trigger class="header-anchor-trigger" to="#29042025">#</doc-anchor-trigger>
        <span>29/04/2025</span>
    </h1>
</doc-anchor-target>
<p>@VicmanGT</p>
<ul>
<li>Started programming code for the Zeus server surveillance using webcam</li>
<li>Face detection algorithms with a Cascade Classifier might be useful</li>
<li>There are different types of configurations for the models managed in .xml files</li>
<li>There were issues when the camera pointed to the side of the face instead of in the front, and in this case there was no prediction</li>
<li>Relevant links:</li>
<li><a href="https://www.geeksforgeeks.org/face-detection-using-cascade-classifier-using-opencv-python/">https://www.geeksforgeeks.org/face-detection-using-cascade-classifier-using-opencv-python/</a></li>
<li><a href="https://chatgpt.com/share/6811b087-52e0-800c-8bbc-b46e9086b737">https://chatgpt.com/share/6811b087-52e0-800c-8bbc-b46e9086b737</a></li>
<li><a href="https://docs.opencv.org/3.4/db/d28/tutorial_cascade_classifier.html">https://docs.opencv.org/3.4/db/d28/tutorial_cascade_classifier.html</a></li>
</ul>
<doc-anchor-target id="todo-10">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#todo-10">#</doc-anchor-trigger>
        <span>Todo:</span>
    </h2>
</doc-anchor-target>
<ul>
<li>Find configuration file that can detect a face completely from the side</li>
<li>Check another way to detect when some is using the computer server</li>
<li>Pose Estimation, Fase Mesh, Eye tracking</li>
<li>Test</li>
</ul>
<doc-anchor-target id="activity-report---30042025">
    <h1>
        <doc-anchor-trigger class="header-anchor-trigger" to="#activity-report---30042025">#</doc-anchor-trigger>
        <span>Activity Report - 30/04/2025</span>
    </h1>
</doc-anchor-target>
<p><strong>Email:</strong> <a href="mailto:brandon@nuclea.solutions">brandon@nuclea.solutions</a></p>
<doc-anchor-target id="main-updates-16">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#main-updates-16">#</doc-anchor-trigger>
        <span>Main Updates</span>
    </h2>
</doc-anchor-target>
<ul>
<li>The Zeus computer was successfully configured to use NVIDIA NGC with access to all containers provided by NVIDIA Metropolis.</li>
<li>The first Docker container for NVIDIA VST was downloaded and used.</li>
<li>The UI was successfully displayed, although I still haven&#x27;t found a way to connect the VST service to the local computer&#x27;s webcam.</li>
<li>It is necessary to investigate how to run the webcam over RTSP and connect it directly to the Docker container so it can detect it, and also check if it would work with access to the camera recordings from Fimex.</li>
</ul>
<doc-anchor-target id="30042025">
    <h1>
        <doc-anchor-trigger class="header-anchor-trigger" to="#30042025">#</doc-anchor-trigger>
        <span>30/04/2025</span>
    </h1>
</doc-anchor-target>
<p>@VicmanGT</p>
<ul>
<li>Found repository that already had implemented a face detection algorithm and was able to detect face from the profile</li>
<li>Had some bugs but they&#x27;re fixed now</li>
<li>Modifications:</li>
<li>Limit face detection to only the one that is closer to the camera by comparing the size of the bounding box</li>
<li>Added threshold to see if the face was close enough, simulating it&#x27;s using the computer server</li>
<li>Filter by &#x27;Right Profile&#x27; according to the accomodation of the webcam in the computer server so when it&#x27;s detected, the code saved the frames and makes a video out of them</li>
<li>Relevant links:</li>
<li><a href="https://github.com/nawafalageel/Side-Profile-Detection">https://github.com/nawafalageel/Side-Profile-Detection</a></li>
<li><a href="https://www.geeksforgeeks.org/python-opencv-capture-video-from-camera/">https://www.geeksforgeeks.org/python-opencv-capture-video-from-camera/</a></li>
</ul>
<doc-anchor-target id="todo-11">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#todo-11">#</doc-anchor-trigger>
        <span>Todo:</span>
    </h2>
</doc-anchor-target>
<ul>
<li>Check how to make multiple videos out of a single stream without the need to rerun the code</li>
</ul>
<doc-anchor-target id="activity-report---02052025">
    <h1>
        <doc-anchor-trigger class="header-anchor-trigger" to="#activity-report---02052025">#</doc-anchor-trigger>
        <span>Activity Report - 02/05/2025</span>
    </h1>
</doc-anchor-target>
<p><strong>Email:</strong> <a href="mailto:brandon@nuclea.solutions">brandon@nuclea.solutions</a></p>
<doc-anchor-target id="main-updates-17">
    <h2>
        <doc-anchor-trigger class="header-anchor-trigger" to="#main-updates-17">#</doc-anchor-trigger>
        <span>Main Updates</span>
    </h2>
</doc-anchor-target>
<ul>
<li>An RTSP service was configured so that the webcam from Nuclea&#x27;s office could be accessed via RTSP streaming.<img src="https://github.com/user-attachments/assets/b61ce0a9-2fab-4214-b8f6-0b5952fc7410" alt="image" /></li>
<li>A separate Docker container was used and configured to manage the VST more effectively.</li>
<li>The streaming from 4 Fimex cameras was successfully added directly to the VST UI for further analysis.<img src="https://github.com/user-attachments/assets/ecb63238-7012-470d-85f0-bb0adc70357e" alt="image" /><img src="https://github.com/user-attachments/assets/dc4d4c34-1403-49ae-a588-eb566a55e01b" alt="image" /></li>
<li>Investigate why the RTSP stream from the webcam did not work within the VST.</li>
<li>Check why I haven&#x27;t been able to draw ROI zones and Tripwires on the Fimex streams that appear.</li>
</ul>

                                
                                <!-- Required only on API pages -->
                                <doc-toolbar-member-filter-no-results></doc-toolbar-member-filter-no-results>
                            </div>
                            <footer id="retype-content-footer" class="clear-both">
                            
                                <nav id="retype-nextprev" class="print:hidden flex mt-14">
                                    <div class="w-1/2">
                                        <a class="px-5 py-4 h-full flex items-center break-normal font-medium text-body-link border border-base-border hover:border-base-border-hover rounded-l-lg transition-colors duration-150 relative hover:z-5" href="../../isaac_sim_lab/reports_05_2025/">
                                            <svg xmlns="http://www.w3.org/2000/svg" class="mr-3" width="24" height="24" viewBox="0 0 24 24" fill="currentColor" overflow="visible"><path d="M19 11H7.41l5.29-5.29a.996.996 0 10-1.41-1.41l-7 7a1 1 0 000 1.42l7 7a1.024 1.024 0 001.42-.01.996.996 0 000-1.41L7.41 13H19c.55 0 1-.45 1-1s-.45-1-1-1z" /><path fill="none" d="M0 0h24v24H0z" /></svg>
                                            <span>
                                                <span class="block text-xs font-normal text-base-text-muted">Previous</span>
                                                <span class="block mt-1">02/05/2025</span>
                                            </span>
                                        </a>
                                    </div>
                            
                                    <div class="w-1/2">
                                        <a class="px-5 py-4 -mx-px h-full flex items-center justify-end break-normal font-medium text-body-link border border-base-border hover:border-base-border-hover rounded-r-lg transition-colors duration-150 relative hover:z-5" href="../../isaac_sim_lab/initial_investigation/">
                                            <span>
                                                <span class="block text-xs font-normal text-right text-base-text-muted">Next</span>
                                                <span class="block mt-1">NVIDIA Isaac Sim & Isaac</span>
                                            </span>
                                            <svg xmlns="http://www.w3.org/2000/svg" class="ml-3" width="24" height="24" viewBox="0 0 24 24" fill="currentColor" overflow="visible"><path d="M19.92 12.38a1 1 0 00-.22-1.09l-7-7a.996.996 0 10-1.41 1.41l5.3 5.3H5c-.55 0-1 .45-1 1s.45 1 1 1h11.59l-5.29 5.29a.996.996 0 000 1.41c.19.2.44.3.7.3s.51-.1.71-.29l7-7c.09-.09.16-.21.21-.33z" /><path fill="none" d="M0 0h24v24H0z" /></svg>
                                        </a>
                                    </div>
                                </nav>
                            </footer>
                        </main>
                
                        <div id="retype-page-footer" class="print:border-none border-t border-base-border pt-6 mb-8">
                            <footer class="flex flex-wrap items-center justify-between print:justify-center">
                                <div id="retype-footer-links" class="print:hidden">
                                    <ul class="flex flex-wrap items-center text-sm">
                                    </ul>
                                </div>
                                <div id="retype-copyright" class="print:justify-center py-2 text-footer-text font-footer-link-weight text-sm leading-relaxed"><p>© Copyright 2025. All rights reserved.</p></div>
                            </footer>
                        </div>
                    </div>
                
                    <!-- Rendered if sidebar right is enabled -->
                    <!-- Sidebar right skeleton-->
                    <div v-cloak class="fixed top-0 bottom-0 right-0 translate-x-full bg-sidebar-right-bg border-sidebar-right-border lg:sticky lg:border-l lg:shrink-0 lg:pt-6 lg:transform-none sm:w-1/2 lg:w-64 lg:z-0 md:w-104 sidebar-right skeleton">
                        <div class="pl-5">
                            <div class="w-32 h-3 mb-4 bg-skeleton-bg rounded-full loading"></div>
                            <div class="w-48 h-3 mb-4 bg-skeleton-bg rounded-full loading"></div>
                            <div class="w-40 h-3 mb-4 bg-skeleton-bg rounded-full loading"></div>
                        </div>
                    </div>
                
                    <!-- User should be able to hide sidebar right -->
                    <doc-sidebar-right v-cloak></doc-sidebar-right>
                </div>

            </div>
        </div>
    
        <doc-search-mobile></doc-search-mobile>
        <doc-back-to-top></doc-back-to-top>
    </div>


    <div id="retype-overlay-target"></div>

    <script data-cfasync="false">window.__DOCS__ = { "title": "27/03/2025", level: 2, icon: "file", hasPrism: false, hasMermaid: false, hasMath: false, tocDepth: 23 }</script>
</body>
</html>
