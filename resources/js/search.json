[[{"l":"Bienvenido al Covenant","p":["Este repositorio hace la función de recopilar las investigaciones y documentación que se han realizado sobre el proyecto Covenant.","Sientanse libre de contribuir con el proyecto."]}],[{"i":"11032025","l":"11/03/2025","p":["solve python version problem in local environment","set up of label studio","set up of test project","set up connection of project with aws s3 bucket"]},{"l":"Pendings","p":["Test the connection between s3 and label studio","Define type of labeling of videos","Define what to do with generated dataset"]},{"i":"12032025","l":"12/03/2025","p":["Created another s3 bucket","Solved problems in connection from label studio to s3 bucket","Defined Source Cloud Storage and Target Cloud Storage","Defined pipeline to extract frames from video","Labeling: person detection (location and count)"]},{"i":"pendings-1","l":"Pendings","p":["Get videos to start to test the labeling","Start labeling","Upload dataset to another s3 bucket"]}],[{"i":"14032025","l":"14/03/2025","p":["Options to make inferences of extracted frames located in the s3 bucket:","Lambda functions","Sagemaker","Lambda function seems to have a simpler and more cost effective implementation","Implemented base code for the Lambda function"]},{"l":"Todo","p":["Make function access frames in s3 bucket","Put configuration of own s3 bucket","Schedule to run every time a new frame is detected in s3 bucket","Test"]},{"i":"18032025","l":"18/03/2025","p":["Configured lambda function in aws","Made firsts test:","Solved library errors by modifing the requirements file","Current Error","https://www.trainyolo.com/blog/deploy-yolov8-on-aws-lambda"]},{"i":"todo-1","l":"Todo","p":["Check possible causes:","Python version","Libraries version","Use SAM to implement whole procedure"]},{"i":"19032025","l":"19/03/2025","p":["Configured SAM and reconfigured lambda function","Solved permisssion errors in AWS user (used all available for needed services, might need to leave only the must-have)","Changed python version from 3.11 to 3.9.21","Changed versions of requirements libraires","Forked repo to develop custom code for the application","Current error:","Analysis and possible solution from AmazonQ"]},{"i":"todo-2","l":"Todo:","p":["Check functionality of app.py and debug","Check possible compatibility issues with libraries","Test with test_api.py","Test using s3 images"]},{"i":"20032025","l":"20/03/2025","p":["Solved all compatibility errors from yesterday","Changed numpy version from 2.x.x to 1.x.x","Testes with test_api.py and worked correctly"]},{"i":"todo-3","l":"Todo:","p":["Implement automatic activation of function when a new image is added in s3 bukcet","Figure out what to do with results"]},{"i":"21032025","l":"21/03/2025","p":["Added code to handle when a new image is added to s3 bucket","Made tests by manually adding image"]},{"i":"todo-4","l":"Todo:","p":["Correrct following errors:","Possbile cause: missing permissions in lambda role","Check problem with generated output of lambda function (no extension aparently)"]},{"i":"24032025","l":"24/03/2025","p":["Corrected permission errors","Added functionality to prediction when a new image is uploaded through workflow to s3 bucket","Tested whole workflow, worked nice"]},{"i":"todo-5","l":"Todo:","p":["Can't save results in s3 bucket when the request succeded, so check where to store them."]},{"i":"26032025","l":"26/03/2025","p":["Added code to uplaod the predictions in a json file to a determined s3 bucket","Error log:"]},{"i":"todo-6","l":"Todo:","p":["Since aws allows only for read files, upload json format in zip package, modify it and then upload to s3 bucket","Test"]}],[{"l":"Lógica conexión cámaras con nube"},{"l":"Configuración de cámara","p":["Acceder a la interfaz web de la cámara","Asignar una ip estática","Habilitar ONVIF","Configurar credenciales","Configurar resolución, fps, bitrate, formato de compresión, etc.","Testear cámaras con ONVIF Device Manager"]},{"l":"Configuración de NVR","p":["NVR en la misma red que las cámaras","Configurar con mismas credenciales que cámaras","Usar auto-discovery para encontrar cámaras con ONVIF (agregar ip manualmente de ser necesario)"]},{"l":"Configuración de grabaciones","p":["Configurar grabación contínua o provocada por una acción(ej detección de movimiento) o cada cierto tiempo","Dividir las grabaciones en segmentos más pequeños (5 min - 10 min) con herramientas como FFmpeg."]},{"l":"Configuración de AWS","p":["Crear bucket en el servicio de S3","Configurar permisos de acceso","AWS Transfer Family soporta FTP, FTPS y SFTP para integrar directamente con s3","Configurar servidor FTP con AWS Transfer Family","Guardar archivos en bucked de AWS"]},{"i":"configuración-de-nvr---aws","l":"Configuración de NVR - AWS","p":["Acceder a interfaz administrativa de NVR","Ingresar dirección del servidor FTP proveída por AWS Transfer Family (si disponible)","Configurar script o AWS CLI en dispositivo externo para hacer la carga","Ingresar credenciales para autenticación","Específicar directorio destino dependiendo de la estructura","Testear conexiones"]},{"l":"Conexión con Label Studio","p":["Llamar a una función (ej AWS Lambda) cuando un video se suba","Generar URL para cada archivo de video","En la llamada a la función hacer un HTTP POST a Label Studio API para crear una tarea","Incluir URL, metadata"]},{"l":"Configuración de Label Studio","p":["Configurar el projecto para manejar videos y definir ripo de etiquetado","Unir resultado (ej archivo JSON) al dataset"]},{"l":"Conceptos"},{"l":"RTSP","p":["Real Time Streaming Protocol, protocolo de control de un servidor de transmisión de medios (video) de manera remota. Se usa para establecer y controlar sesiones de medios entre puntos finales. Los clientes de los servidores de medios emiten comandos como * reproducir, grabar * y pausar, para facilitar el control en tiempo real de la transmisión desde el servidor a un cliente."]},{"l":"ONVIF","p":["Open Network Video Interface Forum, estándar de industria que especifica interfaces comunes para productos de seguridad basadas en ip, como cámaras"]},{"l":"NVR","p":["Network Video Recorder, dispositivo especializado diseñado para recibir, grabar y manejar transmisiones de video digitales desde cámaras IP, el NVR graba el video que ya está en formato digital, normalmente transmitido sobre Ethernet.","Pueden recibir captura de video directamente de cámaras IP, usan cables de conexión estándar, soportan alta resolución, acceso remoto e integración con softwares de manejo de video"]},{"l":"FTP Upload","p":["File Transfer Protocol, protocolo que permite transferir archivos directamente de un dispositivo a otro, las conexiones tienen una relación de cliente y servidor, en el servidor se aloja el contenido y luego te conectas a él como cliente. Los datos se envían a través de los puertos 20 y 21"]},{"l":"HTTP Upload","p":["Usa el Hypertext Transfer Protocol, normalmente en métodos como HTTP POST para mandar archivos a un servidor web o servicio en la nube, puede simplificar la integración con APIs basadas en web y servicios."]},{"l":"Fuentes","p":["https://www.dvraid.com/guide/network-video-recorder-complete-setup-guide/#:~:text=Here%E2%80%99s%20a%20simple%20step-by-step%20process%3A%201%201.Unbox%20the,This%20allows%20you%20to%20access%20the%20NVR%20remotely.","https://chatgpt.com/share/67c8574d-e450-800c-837a-db9e1f3935ef","https://www.videoexpertsgroup.com/glossary/how-to-connect-camera-to-onvif#:~:text=How%20to%20Connect%20an%20IP%20Camera%20via%20ONVIF%3A,Step%205%3A%20Test%20and%20Monitor%20the%20Connection%20","https://aws.amazon.com/es/blogs/storage/collecting-archiving-and-retrieving-surveillance-footage-with-aws/","https://aws.amazon.com/es/blogs/iot/build-a-cloud-gateway-to-ingest-rtsp-video-to-amazon-kinesis-video-streams/","http://labelstud.io.s3-website-us-east-1.amazonaws.com/guide/storage.html#Amazon-S3"]}],[{"l":"Datasets","p":["Entrenamos un modelo de YOLO para encontrar objetos comunes en la construcción"]}],[{"l":"Avances"},{"i":"reporte-de-avances-dia-con-dia-del-etiquetadoultimo-avance","l":"Reporte de avances dia con dia del etiquetado (Ultimo Avance)"},{"i":"07032025","l":"07/03/2025","p":["En dataset","Revisadas","Rechazadas","Sin revisar","Sin etiquetar","9984","0"]}],[{"l":"El Dron","p":["El dron actualmente está equipado con un autopilot de la marca holybro y con el firmware PX4"]},{"l":"Partes","p":["Parte","Descripción","FMU","Pixhawk 6x","Autopilot","Firmware PX4 V1.14"]}],[{"l":"Pruebas de vuelo","p":["Registro de las pruebas de vuelo que se realizan cada semana"]},{"i":"06---mar---2025","l":"06 - Mar - 2025"},{"i":"13---mar---2025","l":"13 - Mar - 2025","p":["@jeduardofr: Build para la AppImage de la version modificada de QGC aunque no se probo debido a errores de dependencias","@jeduardofr: Probar vuelo remoto con mavproxy con dron anclado al suelo, salieron varios detalles como que el dron parecia \"perder\" el control y se aceleraba por su cuenta sin recibir los comandos. La teoria esta en que es debido a como esta anclado el suelo y como el sistema de control reacciona. Sigue pendiente hacer la prueba con el dron ya en vuelo normal.","@fairbrook: Hacer prueba con video con un servidor de video remoto. La prueba fue exitosa. La dirección del servidor es: http://159.54.131.60:8889/comma/ para webrtc y rtsp://159.54.131.60:8554/comma/ para rtsp (util en qground)!!! Estas direcciones van a cambiar en el futuro !!!","@fairbrook y @jeduardofr: Validación de connexión mediante red celular. La comma no detectaba la tarjeta SIM, el modem no detectaba la SIM. El problema fue que el puerto SIM estaba dañado, al revisar a detalle, uno de los pines del puerto estaba doblado y no hacía contacto correctamente. Por lo que la solución fue doblar de vuelta a posición el pin y se corregieron los problemas. Al finalizar la prueba fue exitosa. Comando útiles para el módulo SIM:"]},{"i":"20---mar---2025","l":"20 - Mar - 2025","p":["Este día fue mucho trabajo en equipo para hacer la prueba de vuelo con el dron anclado al suelo.","Configuración de sistema de poleas y cuerdas para mantener al dron dento de un rango de movimiento seguro","Prueba de vuelo exitosa con el sistema de poleas para prevenir caidas del dron al activar el \"kill switch\"","Prueba de vuelo exitosa con el sistema de cuerdas para prevenir colisiones con paredes, objetos y personas","Prueba de vuelo exitosa con el control remoto. Utilizando dos equipos(mavproxy y QGC) y mando de xbox. El fallo de la semana anterior fue que el dron no tenía espacio de movimiento en el eje Z"]},{"i":"24---mar---2025","l":"24 - Mar - 2025","p":["Plan de conexión para la cámara FPV. El diagrma a continuación ejemplifica las interacciones entre los distintos componentees del sistema que permitiría la visualización de la cámara Moonlight en QGC y de forma remota en cualquier dispositivo"]},{"i":"25---mar--2025","l":"25 - Mar -2025","p":["@fairbrook: Hacer prueba con video con un servidor de video remoto. La prueba fue exitosa. Uitilizando OBS y WHIP se pudo hacer una transmisión de video con alta calidad y latencia muy baja ~ 330ms. Al intentar hacer la transmisión de video utilizando el kit de desarrollo Jetson Nano, la calidad fue menor y con una latencia de ~ 1.3s. Por lo que se busca desarrollar un programa que permita la transmisión de video en la paltaforma Jetson Nano al utilizar \"Hardware Encoding\" y WHIP"]},{"i":"01---abr---2025","l":"01 - Abr - 2025","p":["@fairbrook: Pruebas de latencia con video receptor y transmisor montado en dron y en estación de trabajo. Latencia aproximada de 800ms@jeduardofr: Pruebas de vuelo remoto usando puro video (sin observar el dron) con version modificada de joystick (yaw, pitch & roll factors)"]}],[{"i":"27032025","l":"27/03/2025","p":["Installed and configured Ubuntu 20.04 on local laptop with another ssd (dual boot, dual drive)","Got most of the requirements for Isaac Sim ( lacking VRAM (6.4 -> 8) and RAM (14.4 -> 32 ))","Installed Isaac Sim"]},{"i":"todo","l":"Todo:","p":["Start testing and exploring program"]},{"i":"28032025","l":"28/03/2025","p":["Installed Isaac Lab","Made first tests","Quick start with robotic arm and solid cube","Got performance issues:","\"Isaac Sim is not responding\" multiple times","High RAM usage (300 Mb left)","OS frozen multiple times"]},{"i":"todo-1","l":"Todo:","p":["Check if there's a way to increase performance","Keep testing"]},{"i":"31032025","l":"31/03/2025","p":["Installed Nvidia SDK Manager & Docker","Tests of tutorials in Isaac Sim","Worked well in GUI","Problems in interaction with python scripts","Message appearing when trying hot reload in vs code python script:","Last logs when trying to run sudo ./python.sh standalone_examples/api/isaacsim.simulation_app/hello_world.py","Not obvious reason atm"]},{"i":"1042025","l":"1/04/2025","p":["Solved errors from yesterday","There was no clear reason at all","Most likely something went wrong during Isaac Lab instalation","Solution was to reinstall","Made other tutorials in nvidia page","Got performance errors in some of them","Likely cause: Limited VRAM memory in GPU"]},{"i":"activity-report---01042025","l":"Activity Report - 01/04/2025","p":["Email: brandon@nuclea.solutions"]},{"l":"Main Updates","p":["Watched all Multi-Camera Tracking tutorials from Nvidia: Nvidia On-Demand","Reinstalled Ubuntu 22.04, Isaac Sim, libraries, and drivers to prevent compatibility issues and ensure a clean work environment","Encountered issues during initial tracking tests in Isaac Sim, which led me to decide to reinstall everything.","Email: brandon@nuclea.solutions"]},{"i":"main-updates-1","l":"Main Updates","p":["An attempt was made to create a virtual machine in Google Cloud Console using Compute Engine, but the following service errors occurred:","An attempt was made to resolve the error by selecting different hosting zones and various server characteristics, but unfortunately, none were successful. image","Another test will be attempted with AWS to see if it works there."]},{"i":"2042025","l":"2/04/2025","p":["@VicmanGT","Tested different included examples and tutorials in isaacsim packate","Got import errors in examples that tried to use clases defined in other folders","Exmaples that didnt' do that worked correctly","Got initialization error while trying to launch isaac-sim:","Got temporarly solved by rebooting Ubuntu","Not apparent cause yet.","Error seen in Nvidia Forum:","https://forums.developer.nvidia.com/t/cuda-error-999-failed-to-query-cuda-device-count-cuda-deviceordinal-is-invalid/274493","Email: brandon@nuclea.solutions"]},{"i":"main-updates-2","l":"Main Updates","p":["Successfully launch and configure a virtual machine on AWS without encountering server issues or GPU availability limitations by region.","The NVIDIA drivers with CUDA and other libraries were installed to configure Metropolitan NVIDIA.","An attempt was made to configure Metropolitan NVIDIA using Docker, but the following authorization error occurred:","I used DeepStream SDK as an alternative to Docker to perform intelligent video analysis.","I will look for a way to install it tomorrow using a Docker container for only the VTS service."]},{"i":"03042025","l":"03/04/2025","p":["@VicmanGT","Check tutorials and examples from Nvidia Isaac Sim docs page","Started reviewing examples from cameras in the simulation","Printed frames into console and generated images from frames with opencv","Combined examples from a robot (car and arm ) simulation and a camera implementation, worked nicely"]},{"i":"todo-2","l":"Todo:","p":["Get video from simulation using camera","Check how to put multiple cameras and get data from them","Implement in other examples","Email: brandon@nuclea.solutions"]},{"i":"main-updates-3","l":"Main Updates","p":["It was successfully installed and configured DeepStream on the server.","A configuration file was created for DeepStream so that it could run a video through VST.","The video ran correctly, but I have the problem of not being able to visualize it since I'm connected via SSH.","Find a way to display the VST UI."]},{"i":"04042025","l":"04/04/2025","p":["@VicmanGT","Checked humanoids example","Added multiple cameras to simulation in different positions and orientations","Got frames from all of them each a certain amount of time","Converted frames into iamges and store them in file system","Camera 1 first frame 1_camera1_opencv","Camera 2 first frame 1_camera2_opencv","Camera 3 first frame 1_camera3_opencv","Camera 1 second frame 2_camera1_opencv","Camera 2 second frame 2_camera2_opencv","Camera 13 second frame 2_camera3_opencv"]},{"i":"todo-3","l":"Todo:","p":["Modify humanoid movement to they don't fall that quick"]},{"i":"activity-report---07042025","l":"Activity Report - 07/04/2025","p":["Email: brandon@nuclea.solutions"]},{"i":"main-updates-4","l":"Main Updates","p":["The DeepStream configuration for running MP4 videos has been completed. It runs smoothly, although the interface has not yet been viewed.","The setup for running videos via the RTSP protocol in DeepStream has begun, but it is not yet ready due to the lack of a graphics engine with NVIDIA's TensorRT library, which is used for optimizing and running neural networks on GPUs. image","The plan is to follow the quick start guide for multi-camera simulation with AWS, from: Multi_Camera_Sim2Deploy_AWS"]},{"i":"07042025","l":"07/04/2025","p":["@VicmanGT","Implemented 3 cameras in different position in humanoid simulation","Got 1 fps from all of them and were saved in different folders","Used numeric keyboard to move the humanoids throughout the space ( now modified to warehouse environment )","Simulation Results (5x vel):","https://github.com/user-attachments/assets/857a68e0-6a97-43a5-8a4b-a65aecdfccd5","Cameras frames:","https://github.com/user-attachments/assets/37780be7-548c-43ed-ba8e-8d2b6116535b","https://github.com/user-attachments/assets/055b8177-7941-450b-abac-d18915dcbd03","https://github.com/user-attachments/assets/f38c2686-e087-4d51-bd08-f0ae348baad8","Got some issues with slowness of the simulation and response time from the keyboard input, posible cause the frame capture","Neither RAM or VRAM seem an cause"]},{"i":"08042025","l":"08/04/2025","p":["@VicmanGT","Implemented RF-DETR algorithm on code to make predicions on the detected frames for each camera","GitHub Repo: https://github.com/roboflow/rf-detr","Save the images with surrounding boxes with predictions","Got errors while trying this:","This after making a ./python.sh -m pip install rfdetr to install the library to use the model","The error message was showed in console for almost every omni dependent package","Ran ./post_install.sh after rebooting system","New error was this:","Neither the application of any of the examples from isaac sim worked due to the same error","Couldn't yet find a quick solution in the web"]},{"i":"todo-4","l":"Todo:","p":["Reinstall Isaac Sim from scratch","Check installed python libraries with ./python.sh -m pip list before and after trying to install the rfdeter"]}],[{"i":"nvidia-isaac-sim--isaac","l":"NVIDIA Isaac Sim & Isaac","p":["NVIDIA Isaac Sim is a high-fidelity robotics simulation application built on NVIDIA Omniverse. It is designed to help developers:","Design, simulate, test, and train AI-based robots in photorealistic virtual environments","Generate synthetic data for computer vision and sensor-based learning","Integrate with ROS/ROS 2 and other robotics middleware for real-world deployment","Isaac Sim leverages NVIDIA RTX ray tracing, advanced GPU-accelerated PhysX-based physics, and Universal Scene Description (USD) to provide a scalable, modular simulation platform. Its companion tools (such as Isaac Lab) are used for robot learning and reinforcement learning (RL) experiments."]},{"l":"HW Requirements","p":["GPU: RTX 3060 ( will sufice)","RAM: 32 GB ( may be need to upgrade )"]},{"l":"SF Requirements","p":["OS: Ubuntu 20.04 - 24.04 (need to check dual boot options to maximamize local computational power usage)","Docker ( maybe)","VS Code","GPU Drivers","Isaac Sim ( https://docs.isaacsim.omniverse.nvidia.com/4.5.0/installation/install_workstation.html)"]},{"l":"Guides","p":["https://youtu.be/WzkvBSFfLq8?si=6XGnN6NRmXMMZZPb","https://www.nvidia.com/en-us/on-demand/playlist/playList-62b777fa-766f-4773-8ae4-a70e564d7848/"]}],[{"l":"Tinygrad en Covenant","p":["Investigación relacionada a tinygrad y cambios que se han requerido en el proyecto base"]},{"i":"está-listo-para-funcionar-con-yolo-en-la-comma","l":"¿Está listo para funcionar con yolo en la comma?","p":["No."]}],[{"l":"YOLO en Comma3X","p":["Página para alojar la documentación e investación de la utlización de un modelo de YOLO en el proyecto Comma3X de la empresa Comma.ai"]},{"l":"Reporte de Rendimiento del Modelo de Tinygrad en la Comma"},{"l":"Introducción","p":["Este reporte analiza el rendimiento de dos enfoques distintos para la ejecución de modelos de YOLO en la plataforma Comma. Se compararon:","Compilación JIT en Tinygrad: Se utilizó el repositorio de Tinygrad con la herramienta de compilación Just-In-Time (JIT) para optimizar la ejecución del modelo en tiempo real.","Compilación a Thneed: Se empleó el repositorio de OpenPilot con un proceso de compilación adaptado a la Comma, transformando el modelo en el formato Thneed para mejorar su eficiencia."]},{"l":"Compilación JIT en Tinygrad","p":["La compilación Just-In-Time (JIT) permite optimizar la ejecución del modelo en tiempo real, aplicando optimizaciones específicas según el contexto de uso. El codigo de ejemplo de su uso puede verse en el archivo yolov8_onnx_jit.py."]},{"l":"Funcionamiento en Tinygrad","p":["Captura de operaciones: Tinygrad usa TinyJit para almacenar operaciones en jit_cache en lugar de ejecutarlas inmediatamente.","Optimización: Se aplican técnicas como fusión de operaciones, eliminación de redundancias y planificación de memoria.","Compilación de kernels: Se generan kernels optimizados para la GPU utilizando compiladores especializados (por ejemplo, NVCC para CUDA).","Ejecución: Los kernels se ejecutan en la GPU, asegurando un alto rendimiento.","Reutilización: Se almacenan resultados previos en caché para evitar cálculos innecesarios."]},{"l":"Compilación Thneed en OpenPilot"},{"i":"introducción-1","l":"Introducción","p":["El script compile2_nuclea.py permite la conversión de modelos ONNX al formato Thneed, optimizando su ejecución en la plataforma Comma."]},{"l":"Proceso de Compilación","p":["Carga del Modelo:","Se obtiene el modelo ONNX desde una URL o un archivo local.","Generación del Plan de Ejecución (Schedule):","Se ejecuta el modelo con una imagen de entrada.","Se extrae un plan de ejecución optimizado, eliminando operaciones innecesarias.","Transformación a Formato Thneed:","Se convierte el plan de ejecución en un formato compatible con Thneed.","Se guarda el modelo compilado en un archivo.","Pruebas y Validación:","Se compara el modelo Thneed con el modelo ONNX para garantizar la consistencia de los resultados."]},{"l":"Funciones Clave","p":["get_schedule: Obtiene el plan de ejecución del modelo.","schedule_to_thneed: Transforma el plan en formato Thneed.","thneed_test_onnx: Valida la consistencia entre ONNX y Thneed."]},{"l":"Resultados de Rendimiento","p":["Se evaluaron ambos enfoques utilizando modelos de YOLO en formato ONNX con tres tamaños diferentes: mediano, pequeño y nano. Los tiempos de ejecución obtenidos fueron los siguientes:","Tamaño del Modelo","JIT en Tinygrad","Compilación Thneed","Medium","914 ms","2.1 s","Small","822 ms","951 ms","Nano","308 ms","355 ms"]},{"l":"Análisis de Rendimiento","p":["La ejecución con JIT en Tinygrad fue en promedio un 13% más rápida que la compilación con Thneed, sobre todo en modelos pequeños que no tienen mucho que optimizar.","En general, la ejecución con JIT en Tinygrad fue en promedio más rápida que la compilación con Thneed, aprovechando mejor la GPU en cargas de trabajo más grandes como puede notarse con el modelo Medium."]},{"l":"Conclusión","p":["Los resultados muestran que ambos enfoques son viables para la ejecución de modelos en la Comma, con tiempos de respuesta eficientes en los tres tamaños de YOLO probados. Sin embargo, la compilación JIT en Tinygrad aprovechó mejor la GPU, obteniendo un rendimiento significativamente superior en modelos más grandes en comparación con Thneed.","Esto sugiere que, en aplicaciones donde la latencia es crítica, Tinygrad con JIT puede ser una opción más adecuada."]}]]