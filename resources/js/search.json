[[{"l":"Bienvenido al Covenant","p":["Este repositorio hace la función de recopilar las investigaciones y documentación que se han realizado sobre el proyecto Covenant.","Sientanse libre de contribuir con el proyecto."]}],[{"i":"11032025","l":"11/03/2025","p":["solve python version problem in local environment","set up of label studio","set up of test project","set up connection of project with aws s3 bucket"]},{"l":"Pendings","p":["Test the connection between s3 and label studio","Define type of labeling of videos","Define what to do with generated dataset"]},{"i":"12032025","l":"12/03/2025","p":["Created another s3 bucket","Solved problems in connection from label studio to s3 bucket","Defined Source Cloud Storage and Target Cloud Storage","Defined pipeline to extract frames from video","Labeling: person detection (location and count)"]},{"i":"pendings-1","l":"Pendings","p":["Get videos to start to test the labeling","Start labeling","Upload dataset to another s3 bucket"]}],[{"i":"14032025","l":"14/03/2025","p":["Options to make inferences of extracted frames located in the s3 bucket:","Lambda functions","Sagemaker","Lambda function seems to have a simpler and more cost effective implementation","Implemented base code for the Lambda function"]},{"l":"Todo","p":["Make function access frames in s3 bucket","Put configuration of own s3 bucket","Schedule to run every time a new frame is detected in s3 bucket","Test"]},{"i":"18032025","l":"18/03/2025","p":["Configured lambda function in aws","Made firsts test:","Solved library errors by modifing the requirements file","Current Error","https://www.trainyolo.com/blog/deploy-yolov8-on-aws-lambda"]},{"i":"todo-1","l":"Todo","p":["Check possible causes:","Python version","Libraries version","Use SAM to implement whole procedure"]},{"i":"19032025","l":"19/03/2025","p":["Configured SAM and reconfigured lambda function","Solved permisssion errors in AWS user (used all available for needed services, might need to leave only the must-have)","Changed python version from 3.11 to 3.9.21","Changed versions of requirements libraires","Forked repo to develop custom code for the application","Current error:","Analysis and possible solution from AmazonQ"]},{"i":"todo-2","l":"Todo:","p":["Check functionality of app.py and debug","Check possible compatibility issues with libraries","Test with test_api.py","Test using s3 images"]},{"i":"20032025","l":"20/03/2025","p":["Solved all compatibility errors from yesterday","Changed numpy version from 2.x.x to 1.x.x","Testes with test_api.py and worked correctly"]},{"i":"todo-3","l":"Todo:","p":["Implement automatic activation of function when a new image is added in s3 bukcet","Figure out what to do with results"]},{"i":"21032025","l":"21/03/2025","p":["Added code to handle when a new image is added to s3 bucket","Made tests by manually adding image"]},{"i":"todo-4","l":"Todo:","p":["Correrct following errors:","Possbile cause: missing permissions in lambda role","Check problem with generated output of lambda function (no extension aparently)"]},{"i":"24032025","l":"24/03/2025","p":["Corrected permission errors","Added functionality to prediction when a new image is uploaded through workflow to s3 bucket","Tested whole workflow, worked nice"]},{"i":"todo-5","l":"Todo:","p":["Can't save results in s3 bucket when the request succeded, so check where to store them."]},{"i":"26032025","l":"26/03/2025","p":["Added code to uplaod the predictions in a json file to a determined s3 bucket","Error log:"]},{"i":"todo-6","l":"Todo:","p":["Since aws allows only for read files, upload json format in zip package, modify it and then upload to s3 bucket","Test"]}],[{"l":"Lógica conexión cámaras con nube"},{"l":"Configuración de cámara","p":["Acceder a la interfaz web de la cámara","Asignar una ip estática","Habilitar ONVIF","Configurar credenciales","Configurar resolución, fps, bitrate, formato de compresión, etc.","Testear cámaras con ONVIF Device Manager"]},{"l":"Configuración de NVR","p":["NVR en la misma red que las cámaras","Configurar con mismas credenciales que cámaras","Usar auto-discovery para encontrar cámaras con ONVIF (agregar ip manualmente de ser necesario)"]},{"l":"Configuración de grabaciones","p":["Configurar grabación contínua o provocada por una acción(ej detección de movimiento) o cada cierto tiempo","Dividir las grabaciones en segmentos más pequeños (5 min - 10 min) con herramientas como FFmpeg."]},{"l":"Configuración de AWS","p":["Crear bucket en el servicio de S3","Configurar permisos de acceso","AWS Transfer Family soporta FTP, FTPS y SFTP para integrar directamente con s3","Configurar servidor FTP con AWS Transfer Family","Guardar archivos en bucked de AWS"]},{"i":"configuración-de-nvr---aws","l":"Configuración de NVR - AWS","p":["Acceder a interfaz administrativa de NVR","Ingresar dirección del servidor FTP proveída por AWS Transfer Family (si disponible)","Configurar script o AWS CLI en dispositivo externo para hacer la carga","Ingresar credenciales para autenticación","Específicar directorio destino dependiendo de la estructura","Testear conexiones"]},{"l":"Conexión con Label Studio","p":["Llamar a una función (ej AWS Lambda) cuando un video se suba","Generar URL para cada archivo de video","En la llamada a la función hacer un HTTP POST a Label Studio API para crear una tarea","Incluir URL, metadata"]},{"l":"Configuración de Label Studio","p":["Configurar el projecto para manejar videos y definir ripo de etiquetado","Unir resultado (ej archivo JSON) al dataset"]},{"l":"Conceptos"},{"l":"RTSP","p":["Real Time Streaming Protocol, protocolo de control de un servidor de transmisión de medios (video) de manera remota. Se usa para establecer y controlar sesiones de medios entre puntos finales. Los clientes de los servidores de medios emiten comandos como * reproducir, grabar * y pausar, para facilitar el control en tiempo real de la transmisión desde el servidor a un cliente."]},{"l":"ONVIF","p":["Open Network Video Interface Forum, estándar de industria que especifica interfaces comunes para productos de seguridad basadas en ip, como cámaras"]},{"l":"NVR","p":["Network Video Recorder, dispositivo especializado diseñado para recibir, grabar y manejar transmisiones de video digitales desde cámaras IP, el NVR graba el video que ya está en formato digital, normalmente transmitido sobre Ethernet.","Pueden recibir captura de video directamente de cámaras IP, usan cables de conexión estándar, soportan alta resolución, acceso remoto e integración con softwares de manejo de video"]},{"l":"FTP Upload","p":["File Transfer Protocol, protocolo que permite transferir archivos directamente de un dispositivo a otro, las conexiones tienen una relación de cliente y servidor, en el servidor se aloja el contenido y luego te conectas a él como cliente. Los datos se envían a través de los puertos 20 y 21"]},{"l":"HTTP Upload","p":["Usa el Hypertext Transfer Protocol, normalmente en métodos como HTTP POST para mandar archivos a un servidor web o servicio en la nube, puede simplificar la integración con APIs basadas en web y servicios."]},{"l":"Fuentes","p":["https://www.dvraid.com/guide/network-video-recorder-complete-setup-guide/#:~:text=Here%E2%80%99s%20a%20simple%20step-by-step%20process%3A%201%201.Unbox%20the,This%20allows%20you%20to%20access%20the%20NVR%20remotely.","https://chatgpt.com/share/67c8574d-e450-800c-837a-db9e1f3935ef","https://www.videoexpertsgroup.com/glossary/how-to-connect-camera-to-onvif#:~:text=How%20to%20Connect%20an%20IP%20Camera%20via%20ONVIF%3A,Step%205%3A%20Test%20and%20Monitor%20the%20Connection%20","https://aws.amazon.com/es/blogs/storage/collecting-archiving-and-retrieving-surveillance-footage-with-aws/","https://aws.amazon.com/es/blogs/iot/build-a-cloud-gateway-to-ingest-rtsp-video-to-amazon-kinesis-video-streams/","http://labelstud.io.s3-website-us-east-1.amazonaws.com/guide/storage.html#Amazon-S3"]}],[{"l":"Datasets","p":["Entrenamos un modelo de YOLO para encontrar objetos comunes en la construcción"]}],[{"l":"Avances"},{"i":"reporte-de-avances-dia-con-dia-del-etiquetadoultimo-avance","l":"Reporte de avances dia con dia del etiquetado (Ultimo Avance)"},{"i":"07032025","l":"07/03/2025","p":["En dataset","Revisadas","Rechazadas","Sin revisar","Sin etiquetar","9984","0"]}],[{"l":"El Dron","p":["El dron actualmente está equipado con un autopilot de la marca holybro y con el firmware PX4"]},{"l":"Partes","p":["Parte","Descripción","FMU","Pixhawk 6x","Autopilot","Firmware PX4 V1.14"]}],[{"l":"Pruebas de vuelo","p":["Registro de las pruebas de vuelo que se realizan cada semana"]},{"i":"06---mar---2025","l":"06 - Mar - 2025"},{"i":"13---mar---2025","l":"13 - Mar - 2025","p":["@jeduardofr: Build para la AppImage de la version modificada de QGC aunque no se probo debido a errores de dependencias","@jeduardofr: Probar vuelo remoto con mavproxy con dron anclado al suelo, salieron varios detalles como que el dron parecia \"perder\" el control y se aceleraba por su cuenta sin recibir los comandos. La teoria esta en que es debido a como esta anclado el suelo y como el sistema de control reacciona. Sigue pendiente hacer la prueba con el dron ya en vuelo normal.","@fairbrook: Hacer prueba con video con un servidor de video remoto. La prueba fue exitosa. La dirección del servidor es: http://159.54.131.60:8889/comma/ para webrtc y rtsp://159.54.131.60:8554/comma/ para rtsp (util en qground)!!! Estas direcciones van a cambiar en el futuro !!!","@fairbrook y @jeduardofr: Validación de connexión mediante red celular. La comma no detectaba la tarjeta SIM, el modem no detectaba la SIM. El problema fue que el puerto SIM estaba dañado, al revisar a detalle, uno de los pines del puerto estaba doblado y no hacía contacto correctamente. Por lo que la solución fue doblar de vuelta a posición el pin y se corregieron los problemas. Al finalizar la prueba fue exitosa. Comando útiles para el módulo SIM:"]},{"i":"20---mar---2025","l":"20 - Mar - 2025","p":["Este día fue mucho trabajo en equipo para hacer la prueba de vuelo con el dron anclado al suelo.","Configuración de sistema de poleas y cuerdas para mantener al dron dento de un rango de movimiento seguro","Prueba de vuelo exitosa con el sistema de poleas para prevenir caidas del dron al activar el \"kill switch\"","Prueba de vuelo exitosa con el sistema de cuerdas para prevenir colisiones con paredes, objetos y personas","Prueba de vuelo exitosa con el control remoto. Utilizando dos equipos(mavproxy y QGC) y mando de xbox. El fallo de la semana anterior fue que el dron no tenía espacio de movimiento en el eje Z"]},{"i":"24---mar---2025","l":"24 - Mar - 2025","p":["Plan de conexión para la cámara FPV. El diagrma a continuación ejemplifica las interacciones entre los distintos componentees del sistema que permitiría la visualización de la cámara Moonlight en QGC y de forma remota en cualquier dispositivo"]}],[{"i":"27032025","l":"27/03/2025","p":["Installed and configured Ubuntu 20.04 on local laptop with another ssd (dual boot, dual drive)","Got most of the requirements for Isaac Sim ( lacking VRAM (6.4 -> 8) and RAM (14.4 -> 32 ))","Installed Isaac Sim"]},{"i":"todo","l":"Todo:","p":["Start testing and exploring program"]}],[{"i":"nvidia-isaac-sim--isaac","l":"NVIDIA Isaac Sim & Isaac","p":["NVIDIA Isaac Sim is a high-fidelity robotics simulation application built on NVIDIA Omniverse. It is designed to help developers:","Design, simulate, test, and train AI-based robots in photorealistic virtual environments","Generate synthetic data for computer vision and sensor-based learning","Integrate with ROS/ROS 2 and other robotics middleware for real-world deployment","Isaac Sim leverages NVIDIA RTX ray tracing, advanced GPU-accelerated PhysX-based physics, and Universal Scene Description (USD) to provide a scalable, modular simulation platform. Its companion tools (such as Isaac Lab) are used for robot learning and reinforcement learning (RL) experiments."]},{"l":"HW Requirements","p":["GPU: RTX 3060 ( will sufice)","RAM: 32 GB ( may be need to upgrade )"]},{"l":"SF Requirements","p":["OS: Ubuntu 20.04 - 24.04 (need to check dual boot options to maximamize local computational power usage)","Docker ( maybe)","VS Code","GPU Drivers","Isaac Sim ( https://docs.isaacsim.omniverse.nvidia.com/4.5.0/installation/install_workstation.html)"]},{"l":"Guides","p":["https://youtu.be/WzkvBSFfLq8?si=6XGnN6NRmXMMZZPb","https://www.nvidia.com/en-us/on-demand/playlist/playList-62b777fa-766f-4773-8ae4-a70e564d7848/"]}],[{"l":"Tinygrad en Covenant","p":["Investigación relacionada a tinygrad y cambios que se han requerido en el proyecto base"]},{"i":"está-listo-para-funcionar-con-yolo-en-la-comma","l":"¿Está listo para funcionar con yolo en la comma?","p":["No."]}],[{"l":"YOLO en Comma3X","p":["Página para alojar la documentación e investación de la utlización de un modelo de YOLO en el proyecto Comma3X de la empresa Comma.ai"]},{"l":"Reporte de Rendimiento del Modelo de Tinygrad en la Comma"},{"l":"Introducción","p":["Este reporte analiza el rendimiento de dos enfoques distintos para la ejecución de modelos de YOLO en la plataforma Comma. Se compararon:","Compilación JIT en Tinygrad: Se utilizó el repositorio de Tinygrad con la herramienta de compilación Just-In-Time (JIT) para optimizar la ejecución del modelo en tiempo real.","Compilación a Thneed: Se empleó el repositorio de OpenPilot con un proceso de compilación adaptado a la Comma, transformando el modelo en el formato Thneed para mejorar su eficiencia."]},{"l":"Compilación JIT en Tinygrad","p":["La compilación Just-In-Time (JIT) permite optimizar la ejecución del modelo en tiempo real, aplicando optimizaciones específicas según el contexto de uso. El codigo de ejemplo de su uso puede verse en el archivo yolov8_onnx_jit.py."]},{"l":"Funcionamiento en Tinygrad","p":["Captura de operaciones: Tinygrad usa TinyJit para almacenar operaciones en jit_cache en lugar de ejecutarlas inmediatamente.","Optimización: Se aplican técnicas como fusión de operaciones, eliminación de redundancias y planificación de memoria.","Compilación de kernels: Se generan kernels optimizados para la GPU utilizando compiladores especializados (por ejemplo, NVCC para CUDA).","Ejecución: Los kernels se ejecutan en la GPU, asegurando un alto rendimiento.","Reutilización: Se almacenan resultados previos en caché para evitar cálculos innecesarios."]},{"l":"Compilación Thneed en OpenPilot"},{"i":"introducción-1","l":"Introducción","p":["El script compile2_nuclea.py permite la conversión de modelos ONNX al formato Thneed, optimizando su ejecución en la plataforma Comma."]},{"l":"Proceso de Compilación","p":["Carga del Modelo:","Se obtiene el modelo ONNX desde una URL o un archivo local.","Generación del Plan de Ejecución (Schedule):","Se ejecuta el modelo con una imagen de entrada.","Se extrae un plan de ejecución optimizado, eliminando operaciones innecesarias.","Transformación a Formato Thneed:","Se convierte el plan de ejecución en un formato compatible con Thneed.","Se guarda el modelo compilado en un archivo.","Pruebas y Validación:","Se compara el modelo Thneed con el modelo ONNX para garantizar la consistencia de los resultados."]},{"l":"Funciones Clave","p":["get_schedule: Obtiene el plan de ejecución del modelo.","schedule_to_thneed: Transforma el plan en formato Thneed.","thneed_test_onnx: Valida la consistencia entre ONNX y Thneed."]},{"l":"Resultados de Rendimiento","p":["Se evaluaron ambos enfoques utilizando modelos de YOLO en formato ONNX con tres tamaños diferentes: mediano, pequeño y nano. Los tiempos de ejecución obtenidos fueron los siguientes:","Tamaño del Modelo","JIT en Tinygrad","Compilación Thneed","Medium","914 ms","2.1 s","Small","822 ms","951 ms","Nano","308 ms","355 ms"]},{"l":"Análisis de Rendimiento","p":["La ejecución con JIT en Tinygrad fue en promedio un 13% más rápida que la compilación con Thneed, sobre todo en modelos pequeños que no tienen mucho que optimizar.","En general, la ejecución con JIT en Tinygrad fue en promedio más rápida que la compilación con Thneed, aprovechando mejor la GPU en cargas de trabajo más grandes como puede notarse con el modelo Medium."]},{"l":"Conclusión","p":["Los resultados muestran que ambos enfoques son viables para la ejecución de modelos en la Comma, con tiempos de respuesta eficientes en los tres tamaños de YOLO probados. Sin embargo, la compilación JIT en Tinygrad aprovechó mejor la GPU, obteniendo un rendimiento significativamente superior en modelos más grandes en comparación con Thneed.","Esto sugiere que, en aplicaciones donde la latencia es crítica, Tinygrad con JIT puede ser una opción más adecuada."]}]]