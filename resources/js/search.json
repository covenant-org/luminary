[[{"l":"Bienvenido al Covenant","p":["Este repositorio hace la función de recopilar las investigaciones y documentación que se han realizado sobre el proyecto Covenant.","Sientanse libre de contribuir con el proyecto."]}],[{"i":"11032025","l":"11/03/2025","p":["solve python version problem in local environment","set up of label studio","set up of test project","set up connection of project with aws s3 bucket"]},{"l":"Pendings","p":["Test the connection between s3 and label studio","Define type of labeling of videos","Define what to do with generated dataset"]},{"i":"12032025","l":"12/03/2025","p":["Created another s3 bucket","Solved problems in connection from label studio to s3 bucket","Defined Source Cloud Storage and Target Cloud Storage","Defined pipeline to extract frames from video","Labeling: person detection (location and count)"]},{"i":"pendings-1","l":"Pendings","p":["Get videos to start to test the labeling","Start labeling","Upload dataset to another s3 bucket"]}],[{"i":"14032025","l":"14/03/2025","p":["Options to make inferences of extracted frames located in the s3 bucket:","Lambda functions","Sagemaker","Lambda function seems to have a simpler and more cost effective implementation","Implemented base code for the Lambda function"]},{"l":"Todo","p":["Make function access frames in s3 bucket","Put configuration of own s3 bucket","Schedule to run every time a new frame is detected in s3 bucket","Test"]},{"i":"18032025","l":"18/03/2025","p":["Configured lambda function in aws","Made firsts test:","Solved library errors by modifing the requirements file","Current Error","https://www.trainyolo.com/blog/deploy-yolov8-on-aws-lambda"]},{"i":"todo-1","l":"Todo","p":["Check possible causes:","Python version","Libraries version","Use SAM to implement whole procedure"]},{"i":"19032025","l":"19/03/2025","p":["Configured SAM and reconfigured lambda function","Solved permisssion errors in AWS user (used all available for needed services, might need to leave only the must-have)","Changed python version from 3.11 to 3.9.21","Changed versions of requirements libraires","Forked repo to develop custom code for the application","Current error:","Analysis and possible solution from AmazonQ"]},{"i":"todo-2","l":"Todo:","p":["Check functionality of app.py and debug","Check possible compatibility issues with libraries","Test with test_api.py","Test using s3 images"]},{"i":"20032025","l":"20/03/2025","p":["Solved all compatibility errors from yesterday","Changed numpy version from 2.x.x to 1.x.x","Testes with test_api.py and worked correctly"]},{"i":"todo-3","l":"Todo:","p":["Implement automatic activation of function when a new image is added in s3 bukcet","Figure out what to do with results"]},{"i":"21032025","l":"21/03/2025","p":["Added code to handle when a new image is added to s3 bucket","Made tests by manually adding image"]},{"i":"todo-4","l":"Todo:","p":["Correrct following errors:","Possbile cause: missing permissions in lambda role","Check problem with generated output of lambda function (no extension aparently)"]},{"i":"24032025","l":"24/03/2025","p":["Corrected permission errors","Added functionality to prediction when a new image is uploaded through workflow to s3 bucket","Tested whole workflow, worked nice"]},{"i":"todo-5","l":"Todo:","p":["Can't save results in s3 bucket when the request succeded, so check where to store them."]},{"i":"26032025","l":"26/03/2025","p":["Added code to uplaod the predictions in a json file to a determined s3 bucket","Error log:"]},{"i":"todo-6","l":"Todo:","p":["Since aws allows only for read files, upload json format in zip package, modify it and then upload to s3 bucket","Test"]}],[{"l":"Lógica conexión cámaras con nube"},{"l":"Configuración de cámara","p":["Acceder a la interfaz web de la cámara","Asignar una ip estática","Habilitar ONVIF","Configurar credenciales","Configurar resolución, fps, bitrate, formato de compresión, etc.","Testear cámaras con ONVIF Device Manager"]},{"l":"Configuración de NVR","p":["NVR en la misma red que las cámaras","Configurar con mismas credenciales que cámaras","Usar auto-discovery para encontrar cámaras con ONVIF (agregar ip manualmente de ser necesario)"]},{"l":"Configuración de grabaciones","p":["Configurar grabación contínua o provocada por una acción(ej detección de movimiento) o cada cierto tiempo","Dividir las grabaciones en segmentos más pequeños (5 min - 10 min) con herramientas como FFmpeg."]},{"l":"Configuración de AWS","p":["Crear bucket en el servicio de S3","Configurar permisos de acceso","AWS Transfer Family soporta FTP, FTPS y SFTP para integrar directamente con s3","Configurar servidor FTP con AWS Transfer Family","Guardar archivos en bucked de AWS"]},{"i":"configuración-de-nvr---aws","l":"Configuración de NVR - AWS","p":["Acceder a interfaz administrativa de NVR","Ingresar dirección del servidor FTP proveída por AWS Transfer Family (si disponible)","Configurar script o AWS CLI en dispositivo externo para hacer la carga","Ingresar credenciales para autenticación","Específicar directorio destino dependiendo de la estructura","Testear conexiones"]},{"l":"Conexión con Label Studio","p":["Llamar a una función (ej AWS Lambda) cuando un video se suba","Generar URL para cada archivo de video","En la llamada a la función hacer un HTTP POST a Label Studio API para crear una tarea","Incluir URL, metadata"]},{"l":"Configuración de Label Studio","p":["Configurar el projecto para manejar videos y definir ripo de etiquetado","Unir resultado (ej archivo JSON) al dataset"]},{"l":"Conceptos"},{"l":"RTSP","p":["Real Time Streaming Protocol, protocolo de control de un servidor de transmisión de medios (video) de manera remota. Se usa para establecer y controlar sesiones de medios entre puntos finales. Los clientes de los servidores de medios emiten comandos como * reproducir, grabar * y pausar, para facilitar el control en tiempo real de la transmisión desde el servidor a un cliente."]},{"l":"ONVIF","p":["Open Network Video Interface Forum, estándar de industria que especifica interfaces comunes para productos de seguridad basadas en ip, como cámaras"]},{"l":"NVR","p":["Network Video Recorder, dispositivo especializado diseñado para recibir, grabar y manejar transmisiones de video digitales desde cámaras IP, el NVR graba el video que ya está en formato digital, normalmente transmitido sobre Ethernet.","Pueden recibir captura de video directamente de cámaras IP, usan cables de conexión estándar, soportan alta resolución, acceso remoto e integración con softwares de manejo de video"]},{"l":"FTP Upload","p":["File Transfer Protocol, protocolo que permite transferir archivos directamente de un dispositivo a otro, las conexiones tienen una relación de cliente y servidor, en el servidor se aloja el contenido y luego te conectas a él como cliente. Los datos se envían a través de los puertos 20 y 21"]},{"l":"HTTP Upload","p":["Usa el Hypertext Transfer Protocol, normalmente en métodos como HTTP POST para mandar archivos a un servidor web o servicio en la nube, puede simplificar la integración con APIs basadas en web y servicios."]},{"l":"Fuentes","p":["https://www.dvraid.com/guide/network-video-recorder-complete-setup-guide/#:~:text=Here%E2%80%99s%20a%20simple%20step-by-step%20process%3A%201%201.Unbox%20the,This%20allows%20you%20to%20access%20the%20NVR%20remotely.","https://chatgpt.com/share/67c8574d-e450-800c-837a-db9e1f3935ef","https://www.videoexpertsgroup.com/glossary/how-to-connect-camera-to-onvif#:~:text=How%20to%20Connect%20an%20IP%20Camera%20via%20ONVIF%3A,Step%205%3A%20Test%20and%20Monitor%20the%20Connection%20","https://aws.amazon.com/es/blogs/storage/collecting-archiving-and-retrieving-surveillance-footage-with-aws/","https://aws.amazon.com/es/blogs/iot/build-a-cloud-gateway-to-ingest-rtsp-video-to-amazon-kinesis-video-streams/","http://labelstud.io.s3-website-us-east-1.amazonaws.com/guide/storage.html#Amazon-S3"]}],[{"l":"Datasets","p":["Entrenamos un modelo de YOLO para encontrar objetos comunes en la construcción"]}],[{"l":"Avances"},{"i":"reporte-de-avances-dia-con-dia-del-etiquetadoultimo-avance","l":"Reporte de avances dia con dia del etiquetado (Ultimo Avance)"},{"i":"07032025","l":"07/03/2025","p":["En dataset","Revisadas","Rechazadas","Sin revisar","Sin etiquetar","9984","0"]}],[{"l":"El Dron","p":["El dron actualmente está equipado con un autopilot de la marca holybro y con el firmware PX4"]},{"l":"Partes","p":["Parte","Descripción","FMU","Pixhawk 6x","Autopilot","Firmware PX4 V1.14"]}],[{"l":"Pruebas de vuelo","p":["Registro de las pruebas de vuelo que se realizan cada semana"]},{"i":"06---mar---2025","l":"06 - Mar - 2025"},{"i":"13---mar---2025","l":"13 - Mar - 2025","p":["@jeduardofr: Build para la AppImage de la version modificada de QGC aunque no se probo debido a errores de dependencias","@jeduardofr: Probar vuelo remoto con mavproxy con dron anclado al suelo, salieron varios detalles como que el dron parecia \"perder\" el control y se aceleraba por su cuenta sin recibir los comandos. La teoria esta en que es debido a como esta anclado el suelo y como el sistema de control reacciona. Sigue pendiente hacer la prueba con el dron ya en vuelo normal.","@fairbrook: Hacer prueba con video con un servidor de video remoto. La prueba fue exitosa. La dirección del servidor es: http://159.54.131.60:8889/comma/ para webrtc y rtsp://159.54.131.60:8554/comma/ para rtsp (util en qground)!!! Estas direcciones van a cambiar en el futuro !!!","@fairbrook y @jeduardofr: Validación de connexión mediante red celular. La comma no detectaba la tarjeta SIM, el modem no detectaba la SIM. El problema fue que el puerto SIM estaba dañado, al revisar a detalle, uno de los pines del puerto estaba doblado y no hacía contacto correctamente. Por lo que la solución fue doblar de vuelta a posición el pin y se corregieron los problemas. Al finalizar la prueba fue exitosa. Comando útiles para el módulo SIM:"]},{"i":"20---mar---2025","l":"20 - Mar - 2025","p":["Este día fue mucho trabajo en equipo para hacer la prueba de vuelo con el dron anclado al suelo.","Configuración de sistema de poleas y cuerdas para mantener al dron dento de un rango de movimiento seguro","Prueba de vuelo exitosa con el sistema de poleas para prevenir caidas del dron al activar el \"kill switch\"","Prueba de vuelo exitosa con el sistema de cuerdas para prevenir colisiones con paredes, objetos y personas","Prueba de vuelo exitosa con el control remoto. Utilizando dos equipos(mavproxy y QGC) y mando de xbox. El fallo de la semana anterior fue que el dron no tenía espacio de movimiento en el eje Z"]},{"i":"24---mar---2025","l":"24 - Mar - 2025","p":["Plan de conexión para la cámara FPV. El diagrma a continuación ejemplifica las interacciones entre los distintos componentees del sistema que permitiría la visualización de la cámara Moonlight en QGC y de forma remota en cualquier dispositivo"]},{"i":"25---mar--2025","l":"25 - Mar -2025","p":["@fairbrook: Hacer prueba con video con un servidor de video remoto. La prueba fue exitosa. Uitilizando OBS y WHIP se pudo hacer una transmisión de video con alta calidad y latencia muy baja ~ 330ms. Al intentar hacer la transmisión de video utilizando el kit de desarrollo Jetson Nano, la calidad fue menor y con una latencia de ~ 1.3s. Por lo que se busca desarrollar un programa que permita la transmisión de video en la paltaforma Jetson Nano al utilizar \"Hardware Encoding\" y WHIP"]},{"i":"01---abr---2025","l":"01 - Abr - 2025","p":["@fairbrook: Pruebas de latencia con video receptor y transmisor montado en dron y en estación de trabajo. Latencia aproximada de 800ms@jeduardofr: Pruebas de vuelo remoto usando puro video (sin observar el dron) con version modificada de joystick (yaw, pitch & roll factors)"]},{"i":"12---abr---2025","l":"12 - Abr - 2025","p":["@jeduardofr: Configuracion del sensor optico para mejor lectura de distancia vertical (altura). Mantenimiento general del dron."]},{"i":"08---may---2025","l":"08 - May - 2025","p":["@fairbrook: Configuración de antenas de telemetría P900"]},{"i":"09---may---2025","l":"09 - May - 2025","p":["@fairbrook: pruebas de vuelo y recalibracion del dron"]},{"i":"12---may---2025","l":"12 - May - 2025","p":["@fairbrook: Recorrido por c5 Jalisco"]},{"i":"15---may---2025","l":"15 - May - 2025","p":["@fairbrook: Montar y configurar cámaras para el laboratorios de drones"]}],[{"i":"02052025","l":"02/05/2025","p":["@VicmanGT","Now the program starts recording a video when a right face profile is detected","Once the face is not detected or isn't in that position, a timer starts to check the time since the last detection","if 10 secs have transcurred and the face is no detected the video is saved with a time stamt in .mp4 format","if the face is again detected the recording continues","this way, there are no micro videos of a couple frames because the model fails the prediction"]},{"i":"todo","l":"Todo:","p":["Clone code in Zeus to try in its webcam","Implement sound alarm when a right profile is detected"]},{"i":"activity-report---02052025","l":"Activity Report - 02/05/2025","p":["Email: brandon@nuclea.solutions"]},{"l":"Main Updates","p":["An RTSP service was configured so that the webcam from Nuclea's office could be accessed via RTSP streaming. image","A separate Docker container was used and configured to manage the VST more effectively.","The streaming from 4 Fimex cameras was successfully added directly to the VST UI for further analysis. image image","Investigate why the RTSP stream from the webcam did not work within the VST.","Check why I haven't been able to draw ROI zones and Tripwires on the Fimex streams that appear."]},{"i":"activity-report---05052025","l":"Activity Report - 05/05/2025","p":["Email: brandon@nuclea.solutions"]},{"i":"main-updates-1","l":"Main Updates","p":["Several cameras were configured within the VST (Video Stream Toolkit) in order to enable real-time streaming visualization from the Fimex system. This setup allows for continuous monitoring of the video feeds through the VST interface.","Some modifications were made to the existing script to enable local recording of the video streams from the Fimex cameras. The purpose of this change was to improve the recording quality and minimize frame loss, which had been an issue in previous versions of the setup.","An attempt was made to add ROI (Region of Interest) and tripwire tracking to all camera streams using NVIDIA's VST container. However, during testing it was discovered that errors persist in the ROI and tripwire processing logic, preventing the system from correctly handling and analyzing the drawn areas. Further investigation and debugging are required to resolve these issues and ensure accurate event detection.","A new VNC service was created so that we now have two different accesses to the UI of the Zeus computer, with the objective that Victor and I can work on different desktops, so to speak, and avoid conflicts from working at the same time or moving or closing each other's things. image"]},{"i":"05052025","l":"05/05/2025","p":["@VicmanGT","Implemented sound based alarm that sound when a person's right side face is in front of the camera","https://github.com/user-attachments/assets/7112efbc-12bf-48ab-8224-840be2bcf940","Created a requirements.txt to implement code in Zeus server","Cloned code in Zeus server","When tried to run code got following error:","ALSA lib pulse.c:242:(pulse_connect) PulseAudio: Unable to connect: Connection refused","Possible causes are lack of permissions for the user to access the audio in the computer or lack of sound drivers or devices in it"]},{"i":"activity-report---06052025","l":"Activity Report - 06/05/2025","p":["Email: brandon@nuclea.solutions"]},{"i":"main-updates-2","l":"Main Updates","p":["A tunnel was successfully created using RTSP and Ngrok to add the office webcam to the VST. It was configured correctly, although for some unknown reason, the webcam image hasn't been successfully displayed within Nvidia's VST.","Tests were conducted with the Video Wall and Recorded Streams modules to record certain portions of the stream at a specific, configured schedule. image image","There are plans to use the Wowza platform to access public RTSP services with higher quality and test them in the VST for ROI tracking and tripwire analysis.","There is suspicion that the poor quality of the streams from Fimex's cameras may be due to the VPN server having very low hardware specs. I contacted Fernando (head of IT at Fimex) to look for a solution to this problem directly from their side.tection."]},{"i":"06052025","l":"06/05/2025","p":["@VicmanGT","Investigated causes of the error from yesterday","pulseaudio is a general purpose sound server to communicate the software and the hardware, and it's not intalled","Got following error while trying to install it:","A possible solution is to use Pipewire instead, which is basically the same but more recent","Also check if there's an actuall sound device or sound card in the server computer","Also got following video error while ignoring the audio lines in the script:","This error occurs when the index in cv2.VideoCapture(index) surpases the number of available cameras in the device","Tried to access the camera via VCL -> Media -> Open capture device, on both video0 and video1","Check connection with the webcam and Zeus server"]},{"i":"07052025","l":"07/05/2025","p":["@VicmanGT","Started with the function to detect a movement of the camera","The idea of keeping track of an object is possibly not going to work as expected","If for some reason, the detected object is moved or the model confuses the object or stop detecting it there could be a false positive","The best solution at the moment is the direct comparation of two frames","Substract the values of the pixel of each frame in grayscale","If the result if bigger that a certain threshold so the camera has been moved and an alert is generated","More info:","https://www.hackersrealm.net/post/motion-detection-tutorial-using-opencv"]},{"i":"activity-report---07052025","l":"Activity Report - 07/05/2025","p":["Email: brandon@nuclea.solutions"]},{"i":"main-updates-3","l":"Main Updates","p":["A meeting was scheduled with Fernando (IT manager at Fimex) to upgrade the hardware of the VPN server at the factory in order to improve video quality in the camera streamings, so that the corresponding analysis can be performed later. The hardware upgrade was scheduled for Friday, as the server cannot be shut down during the week.","It was researched and confirmed that the VST Docker requires a Jetson device to function correctly, since there are specific libraries for those components.","An attempt was made to test the analysis of the streamings using external libraries (without using VST), but there were many compatibility errors, so it was decided to wait until a Jetson is available to use VST directly and follow the VST documentation ( https://docs.nvidia.com/jetson/jps/setup/quick-start.html)."]},{"i":"activity-report---08052025","l":"Activity Report - 08/05/2025","p":["Email: brandon@nuclea.solutions"]},{"i":"main-updates-4","l":"Main Updates","p":["To begin ruling out possible errors explaining why the camera streamings at Fimex appear poor when played via RTSP, a Python script was created that launches a local RTSP server using the Mediamtx software. A local 4K video downloaded from YouTube was used and streamed at different resolutions—from 144p up to 4K—to visually assess the smoothness and quality.","The script was also modified so that, in addition to streaming the videos at different qualities, it saves them locally in a folder organized by resolution. image","The videos were analyzed, and it was observed that lower-quality videos play more smoothly than higher-quality ones. This is likely due to the frame transmission: fewer frames result in faster transmission, while more frames slow it down slightly—but the differences are minimal.","An attempt will be made to adjust the Fimex streaming configurations to see if lowering the video quality improves streaming smoothness."]},{"i":"activity-report---09052025","l":"Activity Report - 09/05/2025","p":["Email: brandon@nuclea.solutions"]},{"i":"main-updates-5","l":"Main Updates","p":["The Python script was improved using the ffmpeg library to better re-stream local video via RTSP and to download videos in different qualities.","A method was researched to download videos directly from Hikvision software using its API.","A way to run Nvidia’s VST without using Jetson was researched and tested; configuration is ongoing, and further testing is needed to confirm its usability."]},{"i":"09052025","l":"09/05/2025","p":["@VicmanGT","Fully implemented binary mask in the server surveillance","Detects movement of the camera based of the average difference in the pixel of two frames","If it's bigger than threshold then an alarm sounds","Also detects then an object obstructs the camera view, covering also that case","Some case that may affect funcitonality is when the camera is moved slowly the average diffence is small and therefore the alarm is not going to sound","https://github.com/user-attachments/assets/d587df69-1d0a-42c4-83e9-db9111e9a72e"]},{"i":"activity-report---12052025","l":"Activity Report - 12/05/2025","p":["Email: brandon@nuclea.solutions"]},{"i":"main-updates-6","l":"Main Updates","p":["An attempt was made to reinstall and configure the NVIDIA graphics drivers to enable the nvidia-smi command and allow the system to detect the GPU. However, it could not be fully configured, as the message \"Devices not found\" continued to appear.","A solution was sought to download streaming videos without losing quality. A Python script was created that saves the previous 5 minutes of the stream into short video clips. This method preserves both video quality and smooth playback.","Research was conducted on the protocols used by Hikvision's iVMS-4200 software. It was found that it uses a combination of protocols such as ISUP (Inter-System Unified Protocol), RTSP (Real-Time Streaming Protocol), and ONVIF protocol."]},{"i":"12052025","l":"12/05/2025","p":["@VicmanGT","The webcam is working again","Continued investigation of error while trying to initialize pygame audio mixer","Couldn't yet find pages where the specific error was being solved","Added code to select pulseaudio specifically as the audio driver","And the error is different","To keep testing, code was added to ignore the audio in case is not available","Next thing is to add the funcionality of a visual alarm instead of a sound one"]},{"i":"activity-report---13052025","l":"Activity Report - 13/05/2025","p":["Email: brandon@nuclea.solutions"]},{"i":"main-updates-7","l":"Main Updates","p":["Another Python script was created to analyze and obtain the streaming videos from the 16 Fimex cameras, which resulted in 32 channels, as each camera offers a main channel with higher resolution and a secondary channel with lower resolution.","The purpose of this script is to locally save one minute of footage from each camera with a delay of 1 to 5 seconds from the live stream. This recorded video no longer has issues with fluidity or quality, but the downside is that it’s not entirely live.","It was detected that cameras 9, 10, and 11 on their main channel (channel 1) do not correctly record the full minute locally — they only save one literal second. However, the same cameras on their secondary channel (channel 2) do record the full minute correctly. The cause of this issue has not yet been identified.","An attempt was made to reinstall the drivers to get the GPU on the Zeus computer working properly again, in order to transfer the Python script there and run it as a service. However, the system still does not properly detect the graphics card."]},{"i":"activity-report---14052025","l":"Activity Report - 14/05/2025","p":["Email: brandon@nuclea.solutions"]},{"i":"main-updates-8","l":"Main Updates","p":["All drivers, including NVIDIA and CUDA, were completely reconfigured again on the Zeus computer to ensure proper functionality of the 5070 graphics card.","The Python script was improved to record every minute from the 16 camera streams of Fimex and save them locally on ZEUS's 14 TB hard drive.","A service was created to run every time the Zeus computer starts, so that at the 55th second of every minute, it executes the recording script in parallel for all Fimex cameras for later analysis.","Kevin was also assisted in setting up a VNC service with the MATE GUI for the Cronus computer. With this, we now have all three computers — Zeus, Gaia, and Cronus — equipped with a system for remote visualization."]},{"i":"activity-report---15052025","l":"Activity Report - 15/05/2025","p":["Email: brandon@nuclea.solutions"]},{"i":"main-updates-9","l":"Main Updates","p":["The Python script for recording Fimex camera streams was modified to remove the audio from all streams, and the organization for saving the videos was improved by structuring them by day and minute within their respective folders.","A new Docker container was configured using DeepStream together with NVIDIA VST to analyze the RTSP video streams from the cameras. However, the setup has not yet been able to complete the ROI and tripwire mapping on the streams, although an improvement in the smoothness and quality of each stream was observed.","An attempt will be made to run VST locally on the Zeus computer to analyze each saved video individually without relying on a specific NVIDIA Docker container, since there is a suspicion that it only works—or is better optimized—on Jetson devices."]},{"i":"15052025","l":"15/05/2025","p":["@VicmanGT","Fixed audio driver problem by changing from pulseaudio to pipewire","Setup of virtual environment to have better control of library's version","Got past errors:","Fixed with the already found solution"]},{"i":"todo-1","l":"Todo:","p":["Check how to make the script run at all times","Implement robust error handling","Check what causes error message and if it affects:"]},{"i":"activity-report---16052025","l":"Activity Report - 16/05/2025","p":["Email: brandon@nuclea.solutions"]},{"i":"main-updates-10","l":"Main Updates","p":["Another attempt was made to configure VST for analyzing the video streams from some of the Fimex cameras, but it was unsuccessful. The method to draw ROI lines and tripwires in the system has not yet been figured out.","YOLOv5 was installed and configured on Zeus, along with the PyTorch libraries adapted for CUDA version 12.9.","Since VST has not been able to function properly, a local test was conducted using YOLOv5 and a new Python script designed to read all the videos recorded on a specific day for a specific camera, with the purpose of detecting people who appear or pass through each frame of the video. This was the first version of the script, but it still needs improvement.","I also provided support at Elite to restore functionality to a computer that suddenly failed, which was an urgent issue to resolve."]}],[{"i":"27032025","l":"27/03/2025","p":["Installed and configured Ubuntu 20.04 on local laptop with another ssd (dual boot, dual drive)","Got most of the requirements for Isaac Sim ( lacking VRAM (6.4 -> 8) and RAM (14.4 -> 32 ))","Installed Isaac Sim"]},{"i":"todo","l":"Todo:","p":["Start testing and exploring program"]},{"i":"28032025","l":"28/03/2025","p":["Installed Isaac Lab","Made first tests","Quick start with robotic arm and solid cube","Got performance issues:","\"Isaac Sim is not responding\" multiple times","High RAM usage (300 Mb left)","OS frozen multiple times"]},{"i":"todo-1","l":"Todo:","p":["Check if there's a way to increase performance","Keep testing"]},{"i":"31032025","l":"31/03/2025","p":["Installed Nvidia SDK Manager & Docker","Tests of tutorials in Isaac Sim","Worked well in GUI","Problems in interaction with python scripts","Message appearing when trying hot reload in vs code python script:","Last logs when trying to run sudo ./python.sh standalone_examples/api/isaacsim.simulation_app/hello_world.py","Not obvious reason atm"]},{"i":"1042025","l":"1/04/2025","p":["Solved errors from yesterday","There was no clear reason at all","Most likely something went wrong during Isaac Lab instalation","Solution was to reinstall","Made other tutorials in nvidia page","Got performance errors in some of them","Likely cause: Limited VRAM memory in GPU"]},{"i":"activity-report---01042025","l":"Activity Report - 01/04/2025","p":["Email: brandon@nuclea.solutions"]},{"l":"Main Updates","p":["Watched all Multi-Camera Tracking tutorials from Nvidia: Nvidia On-Demand","Reinstalled Ubuntu 22.04, Isaac Sim, libraries, and drivers to prevent compatibility issues and ensure a clean work environment","Encountered issues during initial tracking tests in Isaac Sim, which led me to decide to reinstall everything.","Email: brandon@nuclea.solutions"]},{"i":"main-updates-1","l":"Main Updates","p":["An attempt was made to create a virtual machine in Google Cloud Console using Compute Engine, but the following service errors occurred:","An attempt was made to resolve the error by selecting different hosting zones and various server characteristics, but unfortunately, none were successful. image","Another test will be attempted with AWS to see if it works there."]},{"i":"2042025","l":"2/04/2025","p":["@VicmanGT","Tested different included examples and tutorials in isaacsim packate","Got import errors in examples that tried to use clases defined in other folders","Exmaples that didnt' do that worked correctly","Got initialization error while trying to launch isaac-sim:","Got temporarly solved by rebooting Ubuntu","Not apparent cause yet.","Error seen in Nvidia Forum:","https://forums.developer.nvidia.com/t/cuda-error-999-failed-to-query-cuda-device-count-cuda-deviceordinal-is-invalid/274493","Email: brandon@nuclea.solutions"]},{"i":"main-updates-2","l":"Main Updates","p":["Successfully launch and configure a virtual machine on AWS without encountering server issues or GPU availability limitations by region.","The NVIDIA drivers with CUDA and other libraries were installed to configure Metropolitan NVIDIA.","An attempt was made to configure Metropolitan NVIDIA using Docker, but the following authorization error occurred:","I used DeepStream SDK as an alternative to Docker to perform intelligent video analysis.","I will look for a way to install it tomorrow using a Docker container for only the VTS service."]},{"i":"03042025","l":"03/04/2025","p":["@VicmanGT","Check tutorials and examples from Nvidia Isaac Sim docs page","Started reviewing examples from cameras in the simulation","Printed frames into console and generated images from frames with opencv","Combined examples from a robot (car and arm ) simulation and a camera implementation, worked nicely"]},{"i":"todo-2","l":"Todo:","p":["Get video from simulation using camera","Check how to put multiple cameras and get data from them","Implement in other examples","Email: brandon@nuclea.solutions"]},{"i":"main-updates-3","l":"Main Updates","p":["It was successfully installed and configured DeepStream on the server.","A configuration file was created for DeepStream so that it could run a video through VST.","The video ran correctly, but I have the problem of not being able to visualize it since I'm connected via SSH.","Find a way to display the VST UI."]},{"i":"04042025","l":"04/04/2025","p":["@VicmanGT","Checked humanoids example","Added multiple cameras to simulation in different positions and orientations","Got frames from all of them each a certain amount of time","Converted frames into iamges and store them in file system","Camera 1 first frame 1_camera1_opencv","Camera 2 first frame 1_camera2_opencv","Camera 3 first frame 1_camera3_opencv","Camera 1 second frame 2_camera1_opencv","Camera 2 second frame 2_camera2_opencv","Camera 13 second frame 2_camera3_opencv"]},{"i":"todo-3","l":"Todo:","p":["Modify humanoid movement to they don't fall that quick"]},{"i":"activity-report---07042025","l":"Activity Report - 07/04/2025","p":["Email: brandon@nuclea.solutions"]},{"i":"main-updates-4","l":"Main Updates","p":["The DeepStream configuration for running MP4 videos has been completed. It runs smoothly, although the interface has not yet been viewed.","The setup for running videos via the RTSP protocol in DeepStream has begun, but it is not yet ready due to the lack of a graphics engine with NVIDIA's TensorRT library, which is used for optimizing and running neural networks on GPUs. image","The plan is to follow the quick start guide for multi-camera simulation with AWS, from: Multi_Camera_Sim2Deploy_AWS"]},{"i":"07042025","l":"07/04/2025","p":["@VicmanGT","Implemented 3 cameras in different position in humanoid simulation","Got 1 fps from all of them and were saved in different folders","Used numeric keyboard to move the humanoids throughout the space ( now modified to warehouse environment )","Simulation Results (5x vel):","https://github.com/user-attachments/assets/857a68e0-6a97-43a5-8a4b-a65aecdfccd5","Cameras frames:","https://github.com/user-attachments/assets/37780be7-548c-43ed-ba8e-8d2b6116535b","https://github.com/user-attachments/assets/055b8177-7941-450b-abac-d18915dcbd03","https://github.com/user-attachments/assets/f38c2686-e087-4d51-bd08-f0ae348baad8","Got some issues with slowness of the simulation and response time from the keyboard input, posible cause the frame capture","Neither RAM or VRAM seem an cause"]},{"i":"08042025","l":"08/04/2025","p":["@VicmanGT","Implemented RF-DETR algorithm on code to make predicions on the detected frames for each camera","GitHub Repo: https://github.com/roboflow/rf-detr","Save the images with surrounding boxes with predictions","Got errors while trying this:","This after making a ./python.sh -m pip install rfdetr to install the library to use the model","The error message was showed in console for almost every omni dependent package","Ran ./post_install.sh after rebooting system","New error was this:","Neither the application of any of the examples from isaac sim worked due to the same error","Couldn't yet find a quick solution in the web"]},{"i":"todo-4","l":"Todo:","p":["Reinstall Isaac Sim from scratch","Check installed python libraries with ./python.sh -m pip list before and after trying to install the rfdeter"]},{"i":"activity-report---09042025","l":"Activity Report - 09/04/2025","p":["Email: brandon@nuclea.solutions"]},{"i":"main-updates-5","l":"Main Updates","p":["Early access was requested from NVIDIA through an official application to use their new AI models and camera tracking technologies, such as NVIDIA Metropolis. I am currently waiting for approval. image","Two work plans were developed to extract video footage from HikVision cameras. The first plan involves downloading videos locally via RTSP using the FFmpeg library. A Python script was created to manage all registered cameras listed in a CSV file. The recording duration is customizable, and using cron jobs and system services, we can schedule the script to run at specific times of the day. image","The second plan builds on the first but differs in that instead of storing the videos locally, the footage is uploaded directly to a cloud storage solution such as an AWS S3 bucket.","Tomorrow, we will begin testing with the actual Fimex cameras and evaluate the strategy of also using an SFTP server to store all videos, which will later be processed using NVIDIA Metropolis."]},{"i":"09042025","l":"09/04/2025","p":["@VicmanGT","Reinstalled Isaac Sim and the problem from yesterdy solved, even after installiing de library for the RF-DETR","Correctly implemented RF-DETR algorithm","Correctly saved frames with bounding boxes of predicitons","Improved performance of simulation by lowering the resolution of the cameras (full hd -> hd)","Moved camera positions to get them to capture a wider space","Implemented an option to choose between automated simulation of manual control with the numpad","Started coding the algorithm to detect movement","Results of simulation:","https://github.com/user-attachments/assets/2f4ab757-2c00-4ba6-847a-94ed0731e8e0","Result frames with predicitons","https://github.com/user-attachments/assets/0ff68486-a04d-4fbf-9df4-60e08fe3807f","https://github.com/user-attachments/assets/85516f4c-dab2-4da7-a751-920e4efccdc5"]},{"i":"todo-5","l":"Todo:","p":["The RF-DETR algorithm had problems to identify the humanoids, labeling them as other objects when they were even detected","This could be mainly due to the not human like texture they have, so try to find if there's another texture to cover them","Check another object detection algorithm such as YOLO to compare performance and scores","Implement the move alert function","Figure out how to mantain some form of consistency during the frames passed"]},{"i":"notes","l":"Notes:","p":["Got this error message some times while trying to run the python script","The problem solved trying 2 or 1 more time, no obvious reason atm"]},{"i":"activity-report---10042025","l":"Activity Report - 10/04/2025","p":["Email: brandon@nuclea.solutions@VicmanGT"]},{"i":"main-updates-6","l":"Main Updates","p":["Today, I visited the Fimex factory and worked with Víctor on configuring and extracting video footage from the production cameras, then streaming it via RTSP to the AWS EC2.","Checked the stream via VLC, however this was only possible in Brandon's personal computer most likely because some specific configuration on the Local Fimex computer.","It did work one time on the Local Fimex computer but after changing the camera in the python script, the connection was unable to be setted again, the reason behind this it's still not clear.","We also left the local Fimex computer connected to TeamViewer, so we can access it remotely in the future for further configuration."]},{"i":"activity-report---11042025","l":"Activity Report - 11/04/2025","p":["Email: brandon@nuclea.solutions"]},{"i":"main-updates-7","l":"Main Updates","p":["A basic GUI was downloaded and configured for the AWS EC2 server, and a successful connection was made from a Windows client machine using VNC. image","A daemon service was created so that, upon starting or restarting the server, the mediamtx service would automatically start and run, enabling the reception of video from the RTSP cameras.","A VPN called Kerio was downloaded and configured on the virtual machine to establish a connection between the server and the local Fimex computer. image","A visit was made to Cumbres to perform a drone flight test."]},{"i":"11042025","l":"11/04/2025","p":["@VicmanGT","Went to Cumbres school to help install and configure a sensor to better measure the distance from the ground","Helped performed basic flight operation"]},{"i":"activity-report---14042025","l":"Activity Report - 14/04/2025","p":["Email: brandon@nuclea.solutions"]},{"i":"main-updates-8","l":"Main Updates","p":["Once the VPN was correctly installed and configured on the EC2 server, a service was also created to enable it and connect automatically to the Fimex server every time the server starts.","A service was created so that VNC would start automatically when Linux boots, allowing us to access the graphical interface without having to activate it manually.","It was possible to ping the IP address 172.16.3.122, and the camera stream could already be viewed using the ffplay command. image image","It will be investigated how to save short video locally to process it on the EC2 server."]},{"i":"14042025","l":"14/04/2025","p":["@VicmanGT","Coded a movement alert function that prints to the console when the centroid of a box prediction moves more that a certain threshold","Included logging info to know when the new object are detected, not longer detected or the classs of the prediction changed","Also when there are no predictions for the image","All this for each camera","https://github.com/user-attachments/assets/be6eac17-51a7-4254-bc91-5e1aee0add30","Implemented YOLOv11 model to make predictions on frames"]},{"i":"todo-6","l":"Todo:","p":["Check how to process the outputs of YOLOv11 to draw the rectangles on the image","Adapt function to process the output of YOLOv11","Email: brandon@nuclea.solutions"]},{"i":"main-updates-9","l":"Main Updates","p":["Some issues were fixed during the VPN initialization that were preventing it from properly connecting to the Fimex server.","After successfully configuring the VPN to access all camera streams from Fimex, a Python script was developed to extract specific segments of the live feed and save them locally on the computer. image image","The script will be improved to analyze each of the extracted videos for camera tracking. A more local solution will be implemented, without using NVIDIA Metropolis, since access to the platform has not yet been granted."]},{"i":"15042025","l":"15/04/2025","p":["@VicmanGT","Created repo to have version control in isaac sim code","Completely implemented YOLOv11 algorithm to make predictions for the isaac sim simulation","Assigned camera 2 to this","Tests results:","The YOLO algorithm performed worse than the RFDE, since in most of the frames none of the humanoids were detected","Therefore no moment whatsoever","https://github.com/user-attachments/assets/e668101a-0287-4461-b6dc-8672fbc261bc","Tested movement alert function in local webcam to check with \"real person movement\" worked nicely","https://github.com/user-attachments/assets/419b049d-e30c-460f-8943-aa1d6a6a3602"]},{"i":"todo-7","l":"Todo:","p":["Apply filter for person class and counting"]},{"i":"16042025","l":"16/04/2025","p":["@VicmanGT","Divided humanoid simulation file into modules for more comfortable development","Added named paratemer to script to select the model to use (rf-dert or yolo)","IsaacSim code stop working in local computer","Got same error as in the 8/04/2025 but the procedure didn't work now","Not custom humanoids simulation app or any of the examples are running:","Last logs before shooting down app:","Get frozen while trying to run then suddenly stops","IsaacSim App selector works ok"]},{"i":"todo-8","l":"Todo:","p":["Check RAM and VRAM usage while trying to run a script","Check other versions","Email: brandon@nuclea.solutions"]},{"i":"main-updates-10","l":"Main Updates","p":["Tests were conducted with the cameras to extract videos from Fimex.","A new VNC service was enabled to allow faster and more efficient access to the server.","A service was created to retry the VPN connection to prevent potential data leaks and to improve video retrieval from the cameras.","A solution will be explored to extract all videos from all cameras via streaming and store them in a bucket with a UI to view the streams simultaneously.","Email: brandon@nuclea.solutions"]},{"i":"main-updates-11","l":"Main Updates","p":["A Python script was created to display the streaming of the 20 cameras connected in Fimex through a simple UI. image","Another script was developed to continuously save the camera streams to an AWS S3 bucket. Whether the recording day ends or the script is interrupted due to an error, the recorded footage up to that point is saved automatically.","A Linux service was configured to ensure the script runs automatically at all times, without the need for manual startup.","The setup of a local computer with a 5070 graphics card will begin, aiming to eliminate the need for using AWS EC2 instances."]},{"i":"22042025","l":"22/04/2025","p":["@VicmanGT","Tested custom models with the people counting function and the movement alert:","best.pt","https://github.com/user-attachments/assets/8ae3f7ba-64e9-4b74-9b0e-67b2b45cc418","NucleaDrone-v14-2Class.pt","https://github.com/user-attachments/assets/32f82b47-f2f7-4d12-9719-09a25f5dac72","Both models got similar results","Only minor difference is that best.pt is faster and therefore better and keeping track of people when do fast movements"]},{"i":"23042025","l":"23/04/2025","p":["@VicmanGT","Cloned metropolis-dev repository into ec2 server to access compute there","Made predictions in videos of Fimex with rfde-tf, custom models best.pt and NucleaDrone-v14-2Class.pt","The rf-detr permormed well both at counting and the interaction with the movement_alert","https://github.com/user-attachments/assets/e4544a9c-d994-498d-8d65-57ae532acdf7","The tests made with both best.pt and NucleaDrone-v14-2Class.pt seemed to have less accuracy when detecting people, and only outputed one person in each frame"]},{"i":"todo-9","l":"Todo:","p":["Check what is happening there"]},{"i":"activity-report---24042025","l":"Activity Report - 24/04/2025","p":["Email: brandon@nuclea.solutions"]},{"i":"main-updates-12","l":"Main Updates","p":["The local Nuclea computer with an Nvidia 5070 graphics card was configured to access the Fimex cameras.","VPN and VNC services were created to enable access to the FSTP video from the cameras.","A script was created to run automatically and locally save the video stream from 20 cameras on the computer."]},{"i":"24042025","l":"24/04/2025","p":["@VicmanGT","Corrected script to get better predictions from custom models best.pt and NucleaDrone-v14-2Class.pt","Tested with videos saved from Fimex cameras","best.pt","https://github.com/user-attachments/assets/4187d91b-af04-4b4d-a9da-73f096d703f7","NucleaDrone-v14-2Class.pt","https://github.com/user-attachments/assets/15da1964-4ead-43fd-9658-97365a215acb","Between the two custom models, best.pt got the better results being faster and more accurate","When comparing best.pt with the rf-dert model, both provide good results with the main difference that best.pt sometimes detect more people in the frame however rf-dert got more consistent and stable predictions."]},{"i":"activity-report---25042025","l":"Activity Report - 25/04/2025","p":["Email: brandon@nuclea.solutions"]},{"i":"main-updates-13","l":"Main Updates","p":["The advanced configuration was completed for the Zeus computer to enable remote access to its operating system's UI via VNC. image","The Python script was improved to more efficiently detect recordings or streamings from the cameras simultaneously and correctly save the video output.","The configuration of the Gaia computer is planned to be completed next, with the goal of enabling remote UI access and beginning the installation of software such as Isaac Sim and Isaac Lab."]},{"i":"25042025","l":"25/04/2025","p":["@VicmanGT","Reestructured scripts in metropolis-dev repo into folders","isaac_sim_lab, models ( custom models ), utils ( movement alert and function to annotate yolo detections), and video_analysis","In video_analysis added separate scripts to test models in webcam and with a folder with videos"]},{"i":"activity-report---28042025","l":"Activity Report - 28/04/2025","p":["Email: brandon@nuclea.solutions"]},{"i":"main-updates-14","l":"Main Updates","p":["The new 14TB hard drive was configured and partitioned for the Zeus computer, and a shortcut was created for this drive in the file explorer.","The script for recording FIMEX cameras was modified to save all videos on the new hard drive.","All the initial configurations for the Gaia computer were completed to enable access to the operating system's GUI via a VNC service. Additionally, basic programs such as Visual Studio Code, VLC, Google Chrome, and others were installed. image"]},{"i":"28042025","l":"28/04/2025","p":["@VicmanGT","Cloned local repository from metropolis-dev and adapted code in the Zeus computer for testing the movement alert in the recordings from Fimex","Got following errors:","Seemed like there isn't yet any Pytorch version that supports the installed GPU NVIDIA GeForce RTX 5070 Ti and therefore no models can be used","This happens for both custom models and rf-detr","Relevant links of same problem but using ComfyUI:","https://github.com/comfyanonymous/ComfyUI/issues/7127","https://github.com/comfyanonymous/ComfyUI/discussions/6643","Solved by installing another pytorch version:","Results:","Very similar to the ones made in the EC2 instance, however there were many videos that had a lot of noise that made the detections inaccurate and inconsistent","Example:","https://github.com/user-attachments/assets/5ffefcec-4474-4f50-bb0e-d34da1fe724d","But it seems like it's more of a problem of the cameras themselves."]},{"i":"activity-report---29042025","l":"Activity Report - 29/04/2025","p":["Email: brandon@nuclea.solutions"]},{"i":"main-updates-15","l":"Main Updates","p":["Isaac Sim and Isaac Lab from NVIDIA were downloaded and configured on the Gaia computer. image","The first test of using the VST container on the Zeus computer for elk tracking with the office webcam was conducted.","The VST Docker container runs correctly, but there is an issue where the UI does not display, even though no specific error is thrown. Further investigation is needed to find a way to launch it properly. image"]},{"i":"29042025","l":"29/04/2025","p":["@VicmanGT","Started programming code for the Zeus server surveillance using webcam","Face detection algorithms with a Cascade Classifier might be useful","There are different types of configurations for the models managed in .xml files","There were issues when the camera pointed to the side of the face instead of in the front, and in this case there was no prediction","Relevant links:","https://www.geeksforgeeks.org/face-detection-using-cascade-classifier-using-opencv-python/","https://chatgpt.com/share/6811b087-52e0-800c-8bbc-b46e9086b737","https://docs.opencv.org/3.4/db/d28/tutorial_cascade_classifier.html"]},{"i":"todo-10","l":"Todo:","p":["Find configuration file that can detect a face completely from the side","Check another way to detect when some is using the computer server","Pose Estimation, Fase Mesh, Eye tracking","Test"]},{"i":"activity-report---30042025","l":"Activity Report - 30/04/2025","p":["Email: brandon@nuclea.solutions"]},{"i":"main-updates-16","l":"Main Updates","p":["The Zeus computer was successfully configured to use NVIDIA NGC with access to all containers provided by NVIDIA Metropolis.","The first Docker container for NVIDIA VST was downloaded and used.","The UI was successfully displayed, although I still haven't found a way to connect the VST service to the local computer's webcam.","It is necessary to investigate how to run the webcam over RTSP and connect it directly to the Docker container so it can detect it, and also check if it would work with access to the camera recordings from Fimex."]},{"i":"30042025","l":"30/04/2025","p":["@VicmanGT","Found repository that already had implemented a face detection algorithm and was able to detect face from the profile","Had some bugs but they're fixed now","Modifications:","Limit face detection to only the one that is closer to the camera by comparing the size of the bounding box","Added threshold to see if the face was close enough, simulating it's using the computer server","Filter by 'Right Profile' according to the accomodation of the webcam in the computer server so when it's detected, the code saved the frames and makes a video out of them","Relevant links:","https://github.com/nawafalageel/Side-Profile-Detection","https://www.geeksforgeeks.org/python-opencv-capture-video-from-camera/"]},{"i":"todo-11","l":"Todo:","p":["Check how to make multiple videos out of a single stream without the need to rerun the code"]},{"i":"activity-report---02052025","l":"Activity Report - 02/05/2025","p":["Email: brandon@nuclea.solutions"]},{"i":"main-updates-17","l":"Main Updates","p":["An RTSP service was configured so that the webcam from Nuclea's office could be accessed via RTSP streaming. image","A separate Docker container was used and configured to manage the VST more effectively.","The streaming from 4 Fimex cameras was successfully added directly to the VST UI for further analysis. image image","Investigate why the RTSP stream from the webcam did not work within the VST.","Check why I haven't been able to draw ROI zones and Tripwires on the Fimex streams that appear."]}],[{"i":"nvidia-isaac-sim--isaac","l":"NVIDIA Isaac Sim & Isaac","p":["NVIDIA Isaac Sim is a high-fidelity robotics simulation application built on NVIDIA Omniverse. It is designed to help developers:","Design, simulate, test, and train AI-based robots in photorealistic virtual environments","Generate synthetic data for computer vision and sensor-based learning","Integrate with ROS/ROS 2 and other robotics middleware for real-world deployment","Isaac Sim leverages NVIDIA RTX ray tracing, advanced GPU-accelerated PhysX-based physics, and Universal Scene Description (USD) to provide a scalable, modular simulation platform. Its companion tools (such as Isaac Lab) are used for robot learning and reinforcement learning (RL) experiments."]},{"l":"HW Requirements","p":["GPU: RTX 3060 ( will sufice)","RAM: 32 GB ( may be need to upgrade )"]},{"l":"SF Requirements","p":["OS: Ubuntu 20.04 - 24.04 (need to check dual boot options to maximamize local computational power usage)","Docker ( maybe)","VS Code","GPU Drivers","Isaac Sim ( https://docs.isaacsim.omniverse.nvidia.com/4.5.0/installation/install_workstation.html)"]},{"l":"Guides","p":["https://www.nvidia.com/en-us/on-demand/playlist/playList-62b777fa-766f-4773-8ae4-a70e564d7848/"]}],[{"l":"NVIDIA Jetson","p":["La plataforma de desarrollo de Nvidia Jetson es una de las más populares para el desarrollo de aplicaciones embebidas de inteligencia artificail y robótica. Ofrece unidades de procesamiento compactas y potentes compatibles con el SDK JetPack de Nvidia que permite un desarrollo más rápido y eficiente.","Actualmente (22-04-2025) no se ha determinado si la plataforma Jetson será la plataforma para todos los desarrollos de covenant pero es una de las posibilidades más prometedoras.","Algunas de las funciones que Covenant planea implemntar en la plataforma Jetson son:","Control autónomo del dron: Cálculo de ruta y evasión de obstáculos","Video vigilancia: Monitoreo de situaciones de riesgo mediante el uso de modelos de visión artificial","Retransmisión de video: Enviar el video de la cámara FPV a un servidor para su consumo remoto","El modelo con el que se cuenta acutalmente es:","Jetson Orin Nano 8GB (Super Developer Kit) Jetpack 6.1 (Ubuntu 22.04)"]}],[{"l":"Configuraciones y herramientas","p":["Documentación sobre las diferentes herarmientas y configuraciones que se han utilizado para el desarrollo de los diferentes proyectos implementados sobre la plataforma de desarrollo NVIDIA Jetson"]},{"l":"YOLO","p":["Modelo de detección y segmentación de objetos enfocado en tiempo real, de la mano de Ultralytics.","Para instalar exitosamente la la libreria de Ultralytics siga el siguiente procedimiento:"]},{"l":"1. Actualizar los repositorios"},{"i":"4-crear-un-entorno-virtual-opcional","l":"4. Crear un entorno virtual (opcional)"},{"l":"3. Instalar la libreria de ultralytics","p":["Se pude omitir [export] si no se desea cambiar de formato los archivos de pesos","En versiones recientes de pip, el dependency resolver toma demasiado tiempo para resolver la dependencia adicional de export de ultralytics. Por lo que se recomienda agregar","--use-deprecated=legacy-resolver"]},{"l":"4. Instalar cusParselt","p":["Los comandos mencionados son para las versiones específicas que se encuentran en la jetson. Para posibles actualizaciones visitar el sitio oficial"]},{"l":"5. Instalar PyTorch y Torchvision","p":["Los whl son para la version 6.1 de Jetpack. Para posibles versiones visitar el sitio oficial de Nvidia o la guía de Ultralytics"]},{"l":"6. Instalar onnxruntime","p":["Onnx runtime cambia la versión de numpy por lo que se debe reinstalar una versión en específico"]},{"l":"Tensorrt","p":["Librería de NVIDIA para C++ que facilita inferencias de alto desempeño en unidades de procecsamiento graficas.TensorRT toma una red entrenada, compuesta por una definición y un grupo de pesas y produce un motor de inferencia optimizado","Existen múltiples formas de instalar tensorrt en Jetson. Pero con la que se tuvo éxito fue la siguiente:"]},{"i":"jtop-jetson-stats","l":"Jtop (Jetson Stats)","p":["Programa que muestra estadisticas de la Jetson en tiempo real, como el uso de GPU y que cuenta con interfaz programática en python","Jetson Stats"]},{"l":"Wadi","p":["Wadi es un servicio de streaming que utiliza el protocolo WebRTC para transmitir video en tiempo real a un servidor WHIP. Se utiliza para transmitir el video de la cámara FPV a un servidor para su consumo remoto"]},{"i":"1-clonar-el-repositorio--wadi","l":"1. Clonar el repositorio Wadi"},{"l":"2. Compilar el proyecto"},{"l":"3. Copiar el ejectuable a la carpeta de binarios"},{"l":"4. Crear servicio y regla de udev","p":["Cree los siguientes archivos en la ruta especificada. Estos son ejemplos y pueden cambiar de acuerdo a sus necesidades","Configuraciones y herramientas","El archivo de servicio utiliza el comando sleep para esperar que el servicio de pulseaudio se inicie. No es la mejor forma de hacerlo y puede causar problemas"]}],[{"l":"Tinygrad en Covenant","p":["Investigación relacionada a tinygrad y cambios que se han requerido en el proyecto base"]},{"i":"está-listo-para-funcionar-con-yolo-en-la-comma","l":"¿Está listo para funcionar con yolo en la comma?","p":["No."]}],[{"l":"YOLO en Comma3X","p":["Página para alojar la documentación e investación de la utlización de un modelo de YOLO en el proyecto Comma3X de la empresa Comma.ai"]},{"l":"Reporte de Rendimiento del Modelo de Tinygrad en la Comma"},{"l":"Introducción","p":["Este reporte analiza el rendimiento de dos enfoques distintos para la ejecución de modelos de YOLO en la plataforma Comma. Se compararon:","Compilación JIT en Tinygrad: Se utilizó el repositorio de Tinygrad con la herramienta de compilación Just-In-Time (JIT) para optimizar la ejecución del modelo en tiempo real.","Compilación a Thneed: Se empleó el repositorio de OpenPilot con un proceso de compilación adaptado a la Comma, transformando el modelo en el formato Thneed para mejorar su eficiencia."]},{"l":"Compilación JIT en Tinygrad","p":["La compilación Just-In-Time (JIT) permite optimizar la ejecución del modelo en tiempo real, aplicando optimizaciones específicas según el contexto de uso. El codigo de ejemplo de su uso puede verse en el archivo yolov8_onnx_jit.py."]},{"l":"Funcionamiento en Tinygrad","p":["Captura de operaciones: Tinygrad usa TinyJit para almacenar operaciones en jit_cache en lugar de ejecutarlas inmediatamente.","Optimización: Se aplican técnicas como fusión de operaciones, eliminación de redundancias y planificación de memoria.","Compilación de kernels: Se generan kernels optimizados para la GPU utilizando compiladores especializados (por ejemplo, NVCC para CUDA).","Ejecución: Los kernels se ejecutan en la GPU, asegurando un alto rendimiento.","Reutilización: Se almacenan resultados previos en caché para evitar cálculos innecesarios."]},{"l":"Compilación Thneed en OpenPilot"},{"i":"introducción-1","l":"Introducción","p":["El script compile2_nuclea.py permite la conversión de modelos ONNX al formato Thneed, optimizando su ejecución en la plataforma Comma."]},{"l":"Proceso de Compilación","p":["Carga del Modelo:","Se obtiene el modelo ONNX desde una URL o un archivo local.","Generación del Plan de Ejecución (Schedule):","Se ejecuta el modelo con una imagen de entrada.","Se extrae un plan de ejecución optimizado, eliminando operaciones innecesarias.","Transformación a Formato Thneed:","Se convierte el plan de ejecución en un formato compatible con Thneed.","Se guarda el modelo compilado en un archivo.","Pruebas y Validación:","Se compara el modelo Thneed con el modelo ONNX para garantizar la consistencia de los resultados."]},{"l":"Funciones Clave","p":["get_schedule: Obtiene el plan de ejecución del modelo.","schedule_to_thneed: Transforma el plan en formato Thneed.","thneed_test_onnx: Valida la consistencia entre ONNX y Thneed."]},{"l":"Resultados de Rendimiento","p":["Se evaluaron ambos enfoques utilizando modelos de YOLO en formato ONNX con tres tamaños diferentes: mediano, pequeño y nano. Los tiempos de ejecución obtenidos fueron los siguientes:","Tamaño del Modelo","JIT en Tinygrad","Compilación Thneed","Medium","914 ms","2.1 s","Small","822 ms","951 ms","Nano","308 ms","355 ms"]},{"l":"Análisis de Rendimiento","p":["La ejecución con JIT en Tinygrad fue en promedio un 13% más rápida que la compilación con Thneed, sobre todo en modelos pequeños que no tienen mucho que optimizar.","En general, la ejecución con JIT en Tinygrad fue en promedio más rápida que la compilación con Thneed, aprovechando mejor la GPU en cargas de trabajo más grandes como puede notarse con el modelo Medium."]},{"l":"Conclusión","p":["Los resultados muestran que ambos enfoques son viables para la ejecución de modelos en la Comma, con tiempos de respuesta eficientes en los tres tamaños de YOLO probados. Sin embargo, la compilación JIT en Tinygrad aprovechó mejor la GPU, obteniendo un rendimiento significativamente superior en modelos más grandes en comparación con Thneed.","Esto sugiere que, en aplicaciones donde la latencia es crítica, Tinygrad con JIT puede ser una opción más adecuada."]}],[{"l":"Stack de self-host","p":["wireguard: VPN","pangolin: Reverse proxy con tuneles","minio: Almacenamiento (como S3 de AWS)","beszel: Monitoreo"]},{"l":"Programas utiles para conexiones de red","p":["nc (netcat): conexiones con TCP y UDP","iptables: firewall","tcpdump: inspeccionar trafico de redes"]},{"l":"Ejemplos de comandos","p":["Permitir trafico hacia puerto, proveniente de ip, con protocolo p(tcp, udp, etc.)","Nota: Este comando pondra la regla hasta arriba del listado, lo que significa que se procesara antes que el resto de reglas que se tengan definidas.","Hacer una conexion hacia host con ip y puerto","Escuchar por trafico en cierta interfaz de red hacia cierto puerto"]},{"l":"Recursos utiles","p":["Beginners guide to traffic filtering with nftables","Differences between iptables and nftables explained"]}]]